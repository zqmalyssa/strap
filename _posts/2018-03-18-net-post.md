---
layout: post
title: "路由器、交换机、防火墙等网络设备"
author-id: "zqmalyssa"
tags: [compute, network]
---

计算机中网络相关的学习真的是非常有用，但也很难，需要形成一个体系，对路由器，交换机，防火墙等有最基本的认识，再不断补充

### 一、路由器

首先要了解一些路由器的基本知识

1. 网络部分相同的IPv4地址，可以认为它们归属同一子网
2. 单播，广播（使用255.255.255.255或主机部分全为1的地址，如192.168.1.255/24），多播，任播（只在IPv6中有）
3. IPv6增加到了128bit，用冒号将地址分成8个部分，每个部分长16bit，使用16进制数字表示，IPv6有条简写规则，即前导并连续的0可以省略
4. 每个地址块中前导并连续的0可以省略，全为0的地址块保存一个0，单个连续的只有0组成的地址可以用": :"来替代（但整个地址中只能有一个": :"），IPv4个人计算机一般标记为"127.0.0.1"，IPv6一般标记为"::1"
5. ARP是通过IPv4地址获取MAC地址的网络协议
6. DHCP服务包括三个功能，DHCP服务器功能、DHCP客户端功能，DHCP中继代理功能，获取Ip的方式有4步，客户端对网段内广播DHCPDISCOVER消息，DHCP服务器在网络内广播DHCPOFFER消息，客户端在网络内广播DHCPREQUEST消息，在接收了DHCPACK消息后，客户端就能使用所分配的IP地址

ip隧道与VPN

某个通信协议被其他通信协议封装后进行转发传输的技术称为隧道技术。在处于网络上的**两台路由器**之间设置隧道的话，就可以在路由器之间根据隧道协议构建一条虚拟的通信链路，路由器A接受的原始分组以封装后的形态通过隧道协议被转发到目的地路由器B中。路由器B随后进行解封装，还原分组形态，并以原始形态再次转发到实际的目的地。

由于该技术架设直连通信两地的隧道（虚拟的），因此也称为隧道技术。

隧道协议有类似L2F，PPTP，L2TP这样将数据链路层数据封装于IP分组中的L2隧道协议，还有类似GRE，IPSec这样将网络层分组封装于IP分组中的L3隧道协议，隧道协议多用于构建VPN（Virtual Private Network，虚拟私有网）网络，尤其是使用IPsec构建加密的VPN提供给用户。这时，PC-A和PC-B之间分配的私有地址处于一个网络中，而路由器A和路由器B之间则使用全局地址，在互联网上相连并负责数据的传输。

路由冗余的种类，主备方式（Active-Standby），双活方式（Active-Active），集群方式（Cluster），使用主备方式时，会使用类似VRRP的冗余协议，

VRRP协议（Virtual Router Redundancy Protocol，虚拟路由冗余协议），用于路由器的冗余和复用（想想Keepalived吧），通过该协议，可以将多台路由器组成1个群组，其中1台为活跃设备，其余为备用设备。与此同时，1台路由器既可以属于多个群组，也可以设置成为双活方式，组成N+1的冗余结构。位于同一个群组的路由器之间使用224.0.0.18的组播地址进行通信，交互协议号为112的VRRP控制分组。默认状态时，主设备每隔1秒向群组内的成员发送VRRP通知信息，如果在3秒内群组没有收到来自主设备的消息则判断主设备已经发生故障（想想keepalived的配置），使用多播地址224.0.0.18发送VRRP通告，以1秒为间隔

隧道协议可以分为二层隧道协议和三层隧道协议，其中二层就在数据链路层，它使用帧作为数据的交换单位，也就是说将数据封装在点对点协议（PPP）帧中，而三层隧道协议在网络层中，使用包作为数据交换单位，它将IP包封装在附加的IP包头中通过IP网络互相传送

### 二、交换机

首先要了解一些交换机的基本知识

L3交换机是一种在L2交换机的基础上增加了路由选择功能的网路硬件，能够通过基于ASIC和FPGA的硬件处理高速实现网络功能和转发分组。L2交换机能够基于数据链路层编制的MAC地址，进行数据帧或VLAN的传输工作，L3交换机能够基于位于网络层的IP首部信息，实现路由选择以及分组过滤等功能。

L2交换机可以通过使用VLAN分割广播域，但终端之间的数据帧交换必须位于同一VLAN范围内。对位于不同VLAN上的终端如有通信需求时，则必须使用路由功能，因此需要在网络上额外添加路由器。**L2交换机与路由器组合才能完成跨VLAN的通信，但使用L3交换机则无需其他硬件设备，能够直接完成VLAN的配置和VLAN之间的通信**。现在，越来越多组织的内部网络核心交换机采用L3交换机，L3交换机多用于在由以太网构筑的Intranet内部转发分组，而路由器则大多作为连接互联网和Intranet内网之间的网关来使用。

L3交换机由控制平面（基于CPU的软件处理进行硬件整体控制，负责操作系统管理，管理员用户界面，路由选择协议处理等工作），数据平面（基于ASIC、FPGA、网络处理器的硬件处理来进行实际的数据传输），背板，物理接口（如常见的RJ-45）

除L2交换机外，拥有L3以上功能的交换机统称为多层交换机或高层交换机，能够支持到TCP层级访问控制的交换机称为L4交换机，甚至有些产品能够基于HTTP和HTTPS这类应用层（L7）参数进行负载均衡操作，这类产品可以称为L7交换机，有些厂商将处理到该层的产品与之前的路由器区分开来，作为不同类型的产品进行销售。但所谓的多层交换机，也就是通过基于ASIC或FPGA的硬件处理，来高速进行各层相关业务处理的网络硬件。

这边就要说到**负载均衡器**，其可以是专用设备，也可以是在通用服务器上运行的应用程序。专用设备一般只有以太网接口，**可以说是多层交换机的一种**。也存在拥有分组负载均衡功能的路由器。设备类的如F5 Networks公司的BIG-IP系列，A10 Networks公司的AX系列。负载均衡的几种算法要了解，常见的是轮询（Round Robin），最少连接（Least Connections），加权轮询（Weighted Round Robin），加权最少连接（Weighted Least Connections），IP地址散列，URL散列。

SSL加速是负载均衡设备提供的功能之一，执行该功能的设备内部装置称为SSL加速器。因为SSL通信时候的加密解密比较耗时，通过SSL加速器，对来自客户端的HTTPS请求解密，将其转换为HTTP请求后再转发至实际的服务器上，这样就可以降低服务器CPU的处理负载

高端L3交换机（一般是机框式的），作为企业的**核心交换机**用于数据中心或服务提供商，中端L3交换机（箱式或最大槽数是4的机框交换机），用于将企业的核心交换机和边缘交换机进行汇聚交换，低端L3交换机（箱式交换机或桌面式交换机），作为企业的接入交换机（边缘交换机）

**VLAN**需要熟悉，由1台或者多台交换集线器所组成的1个广播域可以称为是一个**扁平网络（flat network）**。该网络只由L2组成，相互连接的硬件会接收所有网络发来的广播帧，因此，随着连接硬件数量的增加，广播数量也会增加，网络状况也就越发混杂。这种情况下需要采用能够将整个扁平网络进行逻辑分段的VLAN（Virtual LAN）技术。各个VLAN均使用同1个广播域，因此能够控制该域内广播通信的规模（一个交换机下有多个广播域）。交换机通过设置（configuration）能够轻易更改物理端口的属性，使该物理端口附加某个VLAN之中，因此当连接交换机的用户终端发生变化时，也无需更改所对应的物理配线。**VLAN之间的通信需要使用路由选择**，不借助路由器无法与不同VLAN的终端进行通信，因此安全性有可保障。

1. 基于端口的VLAN是指在一台交换机上完成VLAN的构建功能，在交换机上设置VLAN ID信息，将拥有相同VLAN ID的多个端口构成一个VLAN，交换机在初始状态所有端口默认VLAN ID=1，但是使用者可以对任意一个端口进行VLAN ID=2的设置

2. 标签VLAN，**用在需要跨多个交换机创建VLAN时**，一般会用到使用中继端口（trunk port）的标签VLAN（tag VLAN），标签VLAN通过中继端口完成以太网数据帧的收发，以太网需添加4字节IEEE 802.1Q所定义的首部（即VLAN标签信息），包含12bit的VLAN ID，所以最多支持的VLAN数是4096个

3. 本征VLAN，编号为1的VLAN，一般用于管理VLAN，所以最好使用2以上的数值作为新建VLAN的ID

4. 中继端口，向其他交换机传递VLAN编号时，首先需要设置中继端口（trunk port），两台交换机中继端口之间的链路称为中继链路（trunk link）

**交换机接受到来自主机的ARP请求后，在MAC地址表中记录下主机A的信息，由于ARP请求为广播地址，因此交换机会向除接收端口之外的所有端口复制数据帧并进行扩散（flooding），但在VLAN环境下，只有和主机同属于一个VLAN的端口会被扩散到**

**VLAN之间转发数据，一般会使用中继链路连接路由器，通过路由器记性VLAN之间的路由选择，L3交换机内部直接完成VLAN之间的路由选择**

**补充网桥的内容**
网桥（Bridge）是早期的两端口二层网络设备，用来连接不同网段。网桥的两个端口分别有一条独立的交换信道，不是共享一条背板总线，可隔离冲突域。网桥比集线器（Hub）性能更好，集线器上各端口都是共享同一条背板总线的。后来，网桥被具有更多端口、同时也可隔离冲突域的交换机（Switch）所取代。扩展局域网最常见的方法是使用网桥。最简单的网桥有两个端口，复杂些的网桥可以有更多的端口。网桥的每个端口与一个网段相连。网络1和网络2通过网桥连接后，网桥接收网络1发送的数据包，检查数据包中的地址，如果地址属于网络1，它就将其放弃，相反，如果是网络2的地址，它就继续发送给网络2。这样可利用网桥隔离信息，将同一个网络号划分成多个网段（属于同一个网络号），隔离出安全网段，防止其他网段内的用户非法访问。由于网络的分段，各网段相对独立（属于同一个网络号），一个网段的故障不会影响到另一个网段的运行


### 三、防火墙

防火墙有软件型防火墙和硬件型防火墙之分，其中，软件型中有个人防火墙，运行于个人计算机中，用于监控个人计算机与外部网络之间的通信信息，还有网关型防火墙，在计算机网络的网关中设置类似防火墙设备的功能，从而对网络中通信流量进行策略控制，一类是在windows和linux等通用操作系统上安装运行FireWall-1软件和软件型网关防火墙，一类是使用专用设备的硬件型网关防火墙。硬件型防火墙是指通过硬件设备实现的防火墙，外形同路由器形状类似，但网络接口类型一般只支持以太网。

大多数的防火墙中都有安全区域（Security Zone，简称为区域）的概念，即将防火墙上物理接口以及逻辑接口分配至不同的区域中，也就是将与防火墙连接的网段分别划分到不同的区域中，其中，一个网络接口不能属于多个区域。在同一区域内可以自由进行基本通信，但跨区域的通信必须符合安全策略才能完成，防火墙也能够通过安全策略设置发送源或发送目的地等条件，根据是否符合这些条件来判断位于同一区域内的通信是否可行。

**比如互联网被认为Untrust区域，公开服务器被认为DMZ区域(DeMilitarized Zone，非武装区域，DMZ是指由防火墙划分、放置了对外公开服务器的网段，该区域与内部网络是分离开的)，内部网络被认为Trust区域，销售群组网络被认为Sales区域，Trust区域分配Ethernet1、tunnel1、loopback1，Untrust区域分配Ethernet1/2，DMZ分配Ethernet1/5，Sales分配Ethernet1/3**

防火墙的主要功能就是访问控制，通过设置“规则”来实现，每一条规则都指定了需要控制的发送源、目的地以及通信内容等信息。在路由器中，这类访问控制的规则集合称为“访问控制列表”，而在防火墙中则一般称为“安全策略”或“安全规则”，防火墙的安全策略与路由器最大不同就是是否拥有区域的概念，大多数防火墙使用区域作为触发对象，新一代防火墙触发对象还包括应用程序名称和用户名称等信息。防火墙安全示例中并没有从Trust区域向DMZ区域进行通信的表项，对于这类没有出现在安全策略表中的通信行为，防火墙默认执行拒绝的行为。这一决策称为“默认的拒绝”，可设置的安全策略有一定的上限，表项越多，性能也会随之下降。

NAT是通过路由器或防火墙将发送源的私有IP地址转换为全局IP地址，这一转换称为NAT。NAT原本是路由器提供的功能，现在位于网络边界处的防火墙也有此功能，运行该功能的路由器或防火墙一般称为网关（gateway），静态NAT是将NAT之前的地址和NAT之后的地址进行1:1分配，由管理员将信息设置到网关中。动态NAT首先给网关指定一个名为IP地址池的IP地址范围，也是存在1:1分配，但是动态NAT转换后的地址不是由管理员设置。发送源NAT，对发送源的IP地址进行NAT。目的NAT，对发送目的地的IP地址进行NAT。如果地址不够用，网关需要结合使用TCP或UDP的端口号，完成将多个私有地址映射成1个全局地址的转换。这种技术叫做NAPT（Network Address Port Translation），是动态NAT的一种。

路由器，防火墙，VPN专用装置都可以支持IPSec-VPN的功能，各个节点之间使用这些设备创建IPsec隧道并进行连接，就可以完成VPN的构建。还有一类是SSL-VPN，这类VPN就不需要安装客户端了，带Web浏览器即可，使用防火墙允许通过的HTTPS（TCP443）端口。IPSec在网络层实现，而SSL在会话层实现。

DOS攻击，即Denial of Service，无法继续提供服务，还有DDOS攻击，通过多个跳板攻击，制造远超过预先设计的访问量，从而使得被攻击的系统进入无法提供服务的状态。

防火墙防御功能，DOS防御功能，端口扫描防御（TCP端口扫描，UDP端口扫描，0-65535的端口号进行扫描）

### 四、CCNA补充

概念与上方重叠，补充了路由器，交换机的基本操作，很实用。
1. 理解基本内容后需要学习如何**划分子网，这部很关键**，简单的，复杂的，需要一眼看出子网号，掩码，网关，可用的主机，为后面做准备。理解变长子网（VLSM）
a.子网划分是在原本的主机段进行的，跟网络段没有任何关系
b.有A类地址子网划分，B类地址子网划分和C类地址子网划分
c.子网掩码有对应的CIDR值，/8-/15只用于A类网络，/16-/23可用于A类或者B类网络，/24-/30可用于A类、B类、C类网络，A类网络地址好啊，因为可使用所有的子网掩码，网络设计灵活。
d.块得概念，256-子网掩码就是块，从0开始根据块不断增加到掩码值就是所有子网，广播地址是下一个子网号的前一位，那么可使用主机是地址+1到下一个子网号的前两位
2. 思科网络的的一些基本配置
3. 学习IP路由，路由选择过程，路由选择协议，自己在路由器上配置路由
4. 2层交换机生成树（STP），在交换机上进行配置
5. VLAN的作用，在交换机上配置VLAN，端口为access和trunk，各应用在何处，思科的VTP机制
6. ACL的协议，在路由器上进行访问控制，了解常见的配置写法
7. NAT地址转换，3种方式
8. IPv6，三种改造方法，1双栈（都支持），26to4，包装成IPv4，3使用NAT-PT（不常用），最好还是改造成端到端的IPv6

### 五、路由的管理

traceroute的使用(windows中叫做tracert)

```html

yum install traceroute

执行的结果描述：

1. 记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.sina.com ，表示向每个网关发送4个数据包。

2. 有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。

3. 有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。

"traceroute -q 4 www.sina.com",表示每次向网关发送的探测数据包数量为4

"traceroute -m 10 www.wangshihai.com",表示设置的跳转数量为10次

"traceroute -n www.wangshihai.com",表示不显示主机名，只显示IP地址

"traceroute -p 7778 www.wangshihai.com",表示我们探测包使用UDP端口设置7778

"traceroute -r www.wangshihai.com",表示绕过真正的路由，直接发送到网络主机

"traceroute -w 5 www.wangshihai.com",表示我么设置对外发送探测包的等待响应时间设置为5秒

```

TraceRoute的工作原理: 使用ICMP的和使用UDP的。虽然TTL从字面上翻译，是可以存活的时间，但实际上TTL是IP数据包在计算机网络中可以转发的最大跳数。

使用ICMP Echo Request： Echo Reply and TTL-expired. 所以中间任何一个router上如果封了ICMP Echo Request， traceroute就不能工作；如果封了type 11

使用UDP traceroute:

Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器...... traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？

Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。

Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。

https://www.cnblogs.com/machangwei-8/p/10353279.html 这篇比较详细

对于linux和mac的traceroute

1. 从源地址发出一个UDP探测包到目的地址，并将TTL设置为1；

2. 到达路由器时，将TTL减1；

3. 当TTL变为0时，包被丢弃，路由器向源地址发回一个ICMP超时通知（ICMP Time Exceeded Message），内含发送IP包的源地址，IP包的所有内容及路由器的IP地址；

4. 当源地址收到该ICMP包时，显示这一跳路由信息；

5. 重复1～5，并每次设置TTL加1；

6. 直至目标地址收到探测数据包，并返回端口不可达通知（ICMP Port Unreachable）；

7. 当源地址收到ICMP Port Unreachable包时停止traceroute。


1.Linux和Mac OS等系统使用UDP包进行探测，目标端口号默认为33434，每次探测目标端口号加1（如果一条要探测默认的3次，那么这一条的端口号也是+1）。Traceroute故意使用了一个大于 30000 的目标端口号，以保证目标地址收到数据包后能够返回一个“端口不可达”的 ICMP 报文，于是源地址就可将端口不可达报文当作跟踪结束的标志。

2.Traceroute每跳默认发送3个探测包（发包的数量可通过-q进行设置），探测包的返回会受到网络情况的影响。如果防火墙封掉了ICMP的返回信息，那么相应的延时位置会以*显示。如果某台网关阻塞或者某台DNS出现问题，那么相应行的延时会变长。可以加-n 参数来避免DNS解析，以IP格式输出数据。

3.每个探测包都有唯一的标识号，使得Traceroute能够识别返回的包。UDP数据包使用递增的目标端口号进行标识。


对于windows的tracert

1. 从源地址发出一个ICMP请求回显（ICMP Echo Request）数据包到目的地址，并将TTL设置为1；

2. 到达路由器时，将TTL减1；

3. 当TTL变为0时，包被丢弃，路由器向源地址发回一个ICMP超时通知（ICMP Time Exceeded Message），内含发送IP包的源地址，IP包的所有内容及路由器的IP地址；

4. 当源地址收到该ICMP包时，显示这一跳路由信息；

5. 重复1～5，并每次设置TTL加1；

6. 直至目标地址收到探测数据包，并返回ICMP回应答复（ICMPEcho Reply）；

7. 当源地址收到ICMP Echo Reply包时停止tracert。

1.Windows系统使用ICMP请求回显（ICMP Echo Request）数据包进行探测（注意是没有端口的哦，探测方式不一样，seq的数字+1），源地址以目的地址返回的ICMP回应答复（ICMP Echo Reply）作为跟踪结束标志。

2.Traceroute每跳默认发送3个探测包。在未能到达路由器或未返回ICMP超时通知的情况下，相应的延时位置会以*显示。

3.每个探测包都有唯一的标识号，ICMP数据包使用seq进行标识。

可以用wireshark抓包进行查看

所以总结下linux和windows中的区别，其实是两种探测方式和两种终结标志

Windows的 使用ICMP Echo Request(type是8)， Echo Reply and TTL-expired. 源发出ICMP（无端口），最后的destination送回ICMP Echo Reply(type是0)。所以中间任何一个router上如果封了ICMP Echo Request，traceroute就不能工作；如果封了type 11(TTL-expired)， 中间的router全看不到，但能看到packet 到达了最后的destination；如果封了ICMP Echo Reply，中间的全能看到，最后的destination看不到。

Linux的 使用ICMP TTL-expired(type 是11)， ICMP port unreachable(type 是3， code 3)， UDP port >32768，source发出UDP packet， source port使用随机的任何大于32768的高段port#，destinationport #从33434开始每送个probe依此递增，直至33434+29，（cisco router上使用extended-traceroute命令可以修改这个起始的33434 port #），同时TTL从1开始依此递增，直至1+29=30（最多送30个probe)。中间的router送回 ICMP TTL-expired，使得source得知了中间的每一个router，最后的destination送回TTL-expired 和ICMP port unreachable （因为任何主机上都没有应用使用UDP port# >32768这样的高段port#)。所以中间某处封掉UDP port>32768会导致traceroute不工作。封掉TTL超时会使source看不到中间的router（有的router根本不支持回送TTL超时）；封掉type3，code3可能看不到destination.

另外需要知道的是，由于回送TTL-expired的信息需要CPU生成一个packet，必须打断 CPU，为保证其它工作的正常进行，cisco router每隔一秒才处理traceroute，所以在source 上你可能看到中间一路 * * *，但却看得到最后的destination.这时你应知道这是中间的router CPU太忙或者中间路由器不回送TTL-expired包的原因，不必大惊小怪的

但貌似不是全部的中间路由ip，有些包丢失了。
进一步查看traceroute的选项，有一个－z项，基本意思是设置探测包的发送间隔，默认是0，就是连续发送。设置这个的目的
是因为有些路由器设置了icmp rate limit. 继续研究为什么路由器要设置icmp的发送速率。
google之：原来是为了应付DOS攻击，进而限制端口发出的icmp的速率。

sudo traceroute -I www.google.com -z 0.005 -q 1
traceroute to www.google.com (66.249.89.104), 30 hops max, 60 byte packets
 1  10.10.20.1 (10.10.20.1)  1.914 ms
 2  10.10.20.1 (10.10.20.1)  2.109 ms
 3  10.10.10.1 (10.10.10.1)  1.081 ms
 4  115.238.62.113 (115.238.62.113)  2.468 ms
 5  220.191.158.213 (220.191.158.213)  2.177 ms
 6  61.130.125.25 (61.130.125.25)  2.016 ms
 7  220.191.158.241 (220.191.158.241)  2.419 ms
 8  202.97.55.5 (202.97.55.5)  4.757 ms
 9  202.97.33.14 (202.97.33.14)  5.293 ms
10  202.97.33.2 (202.97.33.2)  5.161 ms
11  202.97.33.5 (202.97.33.5)  4.972 ms
12  202.97.5.138 (202.97.5.138)  41.524 ms
13  209.85.255.80 (209.85.255.80)  53.241 ms
14  209.85.249.195 (209.85.249.195)  68.928 ms
15  72.14.236.126 (72.14.236.126)  52.108 ms
16  66.249.89.104 (66.249.89.104)  48.105 ms

所有的信息都看见了，不会像不加参数那样丢失很多

traceroute如果有6跳，一跳默认是3个包，那么tcpdump -i bond0 dst XXXX 的时候一共能看到 6 * 3 = 18个包

再说下route这个命令

```html

// 去10.1.0.0/16网段，查找gw192.168.1.146
route add -net 10.1.0.0/16 gw 192.168.1.146  // route命令配置的路由条目在网络重启后将会失效

```


再说下Nat这个操作

场景1，SNAT：网络内部有10台主机，它们有各自的IP地址，当网络内部的主机与其他网络中的主机通讯时，则会暴露自己的IP地址，如果我们想要隐藏这些主机的IP地址，该怎么办呢

内部网络的报文发送出去时，报文的源IP会被修改，也就是源地址转换：Source Network Address Translation，缩写为SNAT。

外部网络的报文响应时，响应报文的目标IP会再次被修改，也就是目标地址转换：Destinationnetwork address translation，缩写为DNAT。

但是，上述”整个过程”被称为SNAT，因为”整个过程”的前半段使用了SNAT，如果上述”整个过程”的前半段使用了DNAT，则整个过程被称为DNAT，也就是说，整个过程被称为SNAT还是DNAT，取决于整个过程的前半段使用了SNAT还是DNAT。（其实就是请求的发起方是谁，外部请求，前半段是DNAT，就是DNAT，往外请求，前半段是SNAT，就是SNAT）

其实刚才描述的场景不仅仅能够隐藏网络内部主机的IP地址，还能够让局域网内的主机共享公网IP，让使用私网IP的主机能够访问互联网。

比如，整个公司只有一个公网IP，但是整个公司有10台电脑，我们怎样能让这10台电脑都访问互联网呢？我们可以为这10台电脑都配置上各自的私网IP，比如”192.168″这种私网IP，但是互联网是不会路由私网IP的，如果想要访问互联网，则必须使用公网IP，那么，我们就需要想办法，能让这10台主机共享公司仅有的一个公网IP，没错，这与刚才描述的场景其实完全一致，我们只要在路由器上配置公网IP，在私网主机访问公网服务时，报文经过路由器，路由器将报文中的私网IP与端口号进行修改和映射，将其映射为公网IP与端口号，这时，内网主机即可共享公网IP访问互联网上的服务了，NAT表示意图如下

![snat]({{ "/assets/img/network/snat.png" | relative_url}})

综上所述，SNAT不仅能够隐藏网内的主机IP，还能够共享公网IP，这在IPV4地址较为紧张的今天，是非常有用的。（准确应该说SNAPT，带端口的）


场景2，DNAT：公司有自己的局域网，网络中有两台主机作为服务器，主机1提供web服务，主机2提供数据库服务，但是这两台服务器在局域网中使用私有IP地址，只能被局域网内的主机访问，互联网无法访问到这两台服务器，整个公司只有一个可用的公网IP，怎样通过这个公网IP访问到内网中的这些服务呢？我们可以将这个公网IP配置到公司的某台主机或路由器上，然后对外宣称，这个IP地址对外提供web服务与数据库服务，于是互联网主机将请求报文发送给这公网 IP地址，也就是说，此时报文中的目标IP为公网IP，当路由器收到报文后，将报文的目标地址改为对应的私网地址，比如，如果报文的目标IP与端口号为：公网IP+3306，我们就将报文的目标地址与端口改为：主机2的私网IP+3306，同理，公网IP+80端口映射为主机1的私网IP+80端口，当私网中的主机回应对应请求报文时，再将回应报文的源地址从私网IP+端口号映射为公网IP+端口号，再由路由器或公网主机发送给互联网中的主机。

上述过程也牵扯到DNAT与SNAT，但是由于整个过程的前半段使用了DNAT，所以上述过程被称为DNAT

其实，不管是SNAT还是DNAT，都起到了隐藏内部主机IP的作用。

还有一种全Nat模式，就是源地址和目的地址都会更改，相当于LB用自己的后端Ip作为source发送数据包，回来的时候再修改，这种模式可以做连接复用

### 六、负载均衡

负载均衡是个网络设备

`一.  什么是负载均衡`

1）负载均衡（Load Balance）建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。负载均衡有两方面的含义：首先，大量的并发访问或数据流量分担到多台节点设备上分别处理，减少用户等待响应的时间；其次，单个重负载的运算分担到多台节点设备上做并行处理，每个节点设备处理结束后，将结果汇总，返回给用户，系统处理能力得到大幅度提高。

2）简单来说就是：其一是将大量的并发处理转发给后端多个节点处理，减少工作响应时间；其二是将单个繁重的工作转发给后端多个节点处理，处理完再返回给负载均衡中心，再返回给用户。目前负载均衡技术大多数是用于提高诸如在Web服务器、FTP服务器和其它关键任务服务器上的Internet服务器程序的可用性和可伸缩性。

`二. 负载均衡分类`

1）二层负载均衡（mac）
根据OSI模型分的二层负载，一般是用虚拟mac地址方式，外部对虚拟MAC地址请求，负载均衡接收后分配后端实际的MAC地址响应.
2）三层负载均衡（ip）
一般采用虚拟IP地址方式，外部对虚拟的ip地址请求，负载均衡接收后分配后端实际的IP地址响应. (即一个ip对一个ip的转发, 端口全放开)
3）四层负载均衡（tcp）
在三次负载均衡的基础上，即从第四层"传输层"开始, 使用"ip+port"接收请求，再转发到对应的机器。
4）七层负载均衡（http）
从第七层"应用层"开始, 根据虚拟的url或IP，主机名接收请求，再转向相应的处理服务器。

我们运维中最常见的四层和七层负载均衡，这里重点说下这两种负载均衡。
1）四层的负载均衡就是基于IP+端口的负载均衡：在三层负载均衡的基础上，通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。
对应的负载均衡器称为四层交换机（L4 switch），主要分析IP层及TCP/UDP层，实现四层负载均衡。此种负载均衡器不理解应用协议（如HTTP/FTP/MySQL等等）。

实现四层负载均衡的软件有：
F5：硬件负载均衡器，功能很好，但是成本很高。
lvs：重量级的四层负载软件
nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活
haproxy：模拟四层转发，较灵活

2）七层的负载均衡就是基于虚拟的URL或主机IP的负载均衡：在四层负载均衡的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。

对应的负载均衡器称为七层交换机（L7 switch），除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息，实现七层负载均衡。此种负载均衡器能理解应用协议。
实现七层负载均衡的软件有：
haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；
nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；
apache：功能较差
Mysql proxy：功能尚可。

总的来说，一般是lvs做4层负载；nginx做7层负载(也能做4层负载, 通过stream模块，注意stream模块也可以做4层)；haproxy比较灵活，4层和7层负载均衡都能做

`三. 四层和七层负载均衡之间的区别`

1) 从技术原理上分析
所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。（也就是net文中的全Nat？）

画重点，是在做转发，没有建立连接（这边也有特殊情况，full nat模式会在客户端和4层负载建立连接，然后4层和RS也建立连接，路由模式的话应该不需要建连了）

所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。

画重点，是在做代理，也就是负载均衡器需要先和客户端进行连接，才能获得客户端真正的应用层报文，再根据报文中的特定字段，加上负载均衡设置的服务器选择方式，决定最终的内部服务器，负载均衡与客户端以及后端的服务器会分别建立Tcp连接（所以nginx为啥叫做正向代理或者反向代理，是因为需要建立连接的）

四层负载均衡在中间传输层执行，它处理消息的传递，但不考虑消息的内容。例如TCP是网络上Hypertext Transfer Protocol（HTTP）流量的第四层协议。在这一过程中，4层负载均衡会将网络数据包转发到上游服务器，但不会检查数据包的内容，只能通过检查TCP流中的前几个包来做出有限的路由决策。

七层负载均衡不同于四层负载均衡，它在高级应用层上执行，会处理每个消息的实际内容。HTTP是网络上网站流量的主要7层协议。七层负载均衡以比四层负载均衡更复杂的方式路由网络流量，尤其适用于基于TCP的流量（如HTTP）。七层负载均衡会终止网络流量并读取器中消息，它可以根据消息内容（如URL或cookie）做出负载均衡决策。随后，七层负载均衡与选定上有服务器建立新的TCP连接并将请求写入服务器。


简单来说，二者之间的区别
-  七层负载均衡基本都是基于http协议的，适用于web服务器的负载均衡。（nginx）
-  四层负载均衡主要是基于tcp协议报文，可以做任何基于tcp/ip协议的软件的负载均衡。(haproxy、LVS)
-  两者主要区别在于利用的报文所在的层面是不同的，各有各的好处。
-  七层应用负载的好处，是使得整个网络更”智能化“。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，例如Nginx或者Apache上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。
-  四层负载均衡主要是较为灵活，可以作为多种软件的负载均衡器。

举个例子形象的说明：四层负载均衡就像银行的自助排号机，每一个达到银行的客户根据排号机的顺序，选择对应的窗口接受服务；而七层负载均衡像银行大堂经理，先确认客户需要办理的业务，再安排排号。这样办理理财、存取款等业务的客户，会根据银行内部资源得到统一协调处理，加快客户业务办理流程。


这边详细一点了！！！！！！

首先对于HaProxy，首先看下这篇[haproxy](https://www.cnblogs.com/chimeiwangliang/p/8042190.html)
而对于Keepalived，看下这篇[KeepAlived](https://blog.csdn.net/m0_37606574/article/details/111470467)

要明确的是，有集群的概念了，就需要有个叫做VIP的东西，不然谁领头呢，上述两篇文章都有涉及，但要注意的是，这个VIP是作用到一台机器上的，不是虚无缥缈的，一台机器挂了，就会漂移，而不同架构下，对应的VIP的承载体是不一样的（这也导致一些Confused），要具体想一想

起因是


fan.xxx.xxxcorp.com.  ->  fan.xxx.xxxdns.com. -> 10.15.198.4 或者 10.58.129.134 的一些疑惑

首先这是两个数据中心的VIP，A数据中心和B数据中心，是入口，对应的是两个数据中心的4层负载均衡（硬件NS，F5，AX，软件LVS，DPDK等等），软4层单机性能差，但是集群模式，扩展性强

这个VIP是要配置在4层负载设备上的（硬件软件分别怎么配置？）

而在7层SLB上我们也能查询到这个VIP（为啥这个VIP跟7层有关呢，大致是因为 域名的申请是落在了SLb上，但是域名解析总会有个Ip（也就是上面的VIP），所以相当于7层与入口侧的一个联系，而更前端的gslb是不支持cname的（只能A记录），如果能直接cname，是不是就不需要建立这种联系了？）

其实4层跟7层建立连接的时候跟这个VIP没啥关系

```html

比如fan.xxx.xxxcorp.com 指向的 10.58.129.134， 一个VIP，配置在某套4层上

fan.xxx.xxxcorp.com 实际运行的机器是 10.60.117.207，一个后端服务，开放8080

我们 netstat -anp | grep 10.60.117.207:8080

tcp        0      0 10.60.117.207:8080      10.61.74.14:35411       ESTABLISHED -

这个10.61.74.14是SLB集群中的一台机器，也就是一台nginx

我们再到10.61.74.14上看 netstat -anp | grep 10.61.74.14:80 （注意这边是80，nginx上的是80口，通过/api的path再区分是前端还是后端，7层的作用，/api的后端成员就是8080端口，没有的后端成员就是80端口）

tcp        0      0 10.61.74.14:80          10.58.132.83:42255      ESTABLISHED 20646/nginx: worker

10.58.132.83 这个是什么Ip呢，看着跟VIP 10.58.129.134近似，但不是VIP，这个是SNAT Pool中的Ip

也就是4层和7层的机器建连是 SNAT Pool跟7层机器的建连

7层跟应用机器的建连是 7层机器跟实际应用服务器的建连

```

负载均衡将收到的客户端的数据包进行修改并转发到后端真实服务器，这种修改方式跟后端真实服务器的网络环境有密切关系

四层负载均衡做的主要工作是转发，那就存在一个转发模式的问题，目前主要有四层转发模式：DR模式、NAT模式、TUNNEL模式、FULLNAT模式。

1、路由模式：

又称为网关模式（也有得地方叫做NAT模式），将到达负载均衡的目的Ip地址转变

电脑（192.51.100.75），目的地址203.0.113.2（负载均衡用的VIP）

修改成 源地址 192.51.100.75，目的地址 192.168.1.101

反包的时候就要反过来

源地址 192.168.1.101 目的地址 192.51.100.75

变成

源地址 203.0.113.2 目的地址 192.51.100.75

开始做DNAT，后面做SNAT，前半程是DNAT，所以整个是DNAT

比较常见的部署方式，能获取用户真实IP，会对已有的网络架构进行较大的改动，使后端服务器所有的流量都经过负载均衡器，当同网段服务器访问VIP时，需要在后端服务器上配置主机路由。无法在此种模式下启动连接复用

也有的说是应用服务器无需做配置，但负载均衡必须以网关的形式存在，

NAT模式通过修改数据包的目的IP地址，让流量到达应用服务器，这样做的好处是数据包的目的IP就是应用服务器的IP，因此不需要再在应用服务器上配置VIP了。缺点是由于这种模式修改了目的IP地址，这样如果应用服务器直接将应答包发给客户端的话，其源IP是应用服务器的IP，客户端就不会正常接收这个应答，因此我们需要让流量继续回到负载均衡，负载均衡将应答包的源IP改回VIP再发到客户端，这样才可以保证正常通信，所以NAT模式要求负载均衡需要以网关的形式存在于网络中。

2、单臂模式：

又称为全NAT模式，源IP地址和目的IP地址都要改变，最为常用，对现网改动最小，只有访问VIP的流量才会经过负载均衡器，后端服务器无法获得真实IP（在NAT模式的基础上再做一次SNAT）

源地址 192.51.100.75 目的地址 203.0.113.2

变成

源地址 203.0.113.50 目的地址 203.0.113.101

反过来

源地址 203.0.113.101 目的地址 203.0.113.50

变成

源地址 203.0.113.2 目的地址 192.51.100.75

主要这个203.0.113.50就是SNAT！！！！（所以如果采用这种模式，4层与SLB建连的是这个SNAT的IP？？注意，是书上写的SNAT）


MT说 做SNAT的好处是可以让应答流量经过正常的三层路由回到负载均衡上，这样负载均衡就不需要以网关的形式存在于网络中了（可以存在于任何地方？？），对网络环境要求比较低，缺点是由于做了SNAT，应用服务器会丢失客户端的真实IP地址。

MT的例子 首先负载均衡上需要存在一个localip池，在做SNAT时的源IP就是从localip池中选择的（哦~ 这就是SNAT_POOL了吧）。当客户端流量到达负载均衡设备以后，负载均衡会根据调度策略在应用服务器池中选择一个应用服务器，然后将数据包的目的IP改为应用服务器的IP。同时从localip池中选择一个localip将数据包的源IP改为localip，这样应用服务器在应答时，目的IP是localip，而localip是真实存在于负载均衡上的IP地址，因此可以经过正常的三层路由到达负载均衡。由于FULLNAT比NAT模式多做了一次SNAT，并且SNAT中有选端口的操作，因此其性能要逊色于NAT模式，但是由于其较强的网络环境适应性，我们选择了FULLNAT作为MT的转发模式。

选择自研四层负载均衡的原因主要有两个：第一个是考虑到硬件负载均衡成本比较高；第二个，随着MT业务流量越来越大，LVS出现了性能瓶颈以及运维成本的上升问题。

3、DSR（DR）模式：

又称为三角传输模式，到达负载均衡数据包的目标MAC地址修改了，后端服务器响应数据不经过负载均衡器，适合请求量小，但响应量大的场景，如数据库查询，视频点播等，无法进行连接复用，应用直接回给客户端，性能更好，缺点就是必须在一个二层，应用服务器需要配置VIP（因为没有经过负载均衡中介，多个应用服务器，算谁的呢？得有个VIP）

4、TUNNEL模式：

TUNNEL模式的优缺点和DR是一样的，并且TUNNEL模式要求应用服务器必须支持TUNNEL功能。当然也要配置VIP

为什么要硬转软

硬件负载均衡成本问题
（1）硬件成本：中低端硬件负载均衡价格在数十万，高端的上百万，价格非常昂贵。当我们需要组成一个高可用集群时，需要数台机器，成本异常高。
（2）人力成本：硬件负载均衡功能比较强大，配置比较灵活，这也导致在维护上，我们需要一些经过专业培训的人员，就增加了人力成本。
（3）时间成本：当使用的过程中遇到bug或者新需求需要厂商提供新版本的时候，我们需要经过繁琐的流程向厂商上报，然后厂商再发布新版本供我们升级，时间周期非常长，在高速发展的互联网行业，这种周期是无法接受的

LVS + Nginx为啥不行，因为LVS有瓶颈了，以下：

中断问题以及协议栈路径性能过长问题

中断是影响LVS性能最重要的一个因素，假如我们一秒需要处理600万的数据包，每6个数据包产生一个硬件中断的话，那一秒就会产生100万个硬件中断，每一次产生硬件中断都会打断正在进行密集计算的负载均衡程序，中间产生大量的cache miss，对性能的影响异常大。

同时由于LVS是基于内核netfilter开发的一个应用程序，而netfilter是运行在内核协议栈的一个钩子框架。这就意味着当数据包到达LVS时，已经经过了一段很长的协议栈处理，但是这段处理对于LVS来说都不是必需的，这也造成了一部分不必要的性能损耗。

针对这两个问题，解决方法是使用轮询模式的驱动以及做kernel bypass，而DPDK提供的用户态PMD驱动恰好可以解决这两个问题。DPDK在设计时使用了大量硬件相关特性比如numa、 memory channel、 DDIO等，对性能优化非常大，同时提供了比较多网络方面的库，可以大大减小开发难度，提高开发效率。因此选择DPDK作为MT的开发框架。


所以，作为入口，总有一个VIP作为口子，硬件可以做主备

总结一下

基本上可以推测SNAT Pool的作用

另外，SLb上建立域名是？也就是nginx建立域名是？

j去看SLB，ipam里查SNAT Pool Ip

nginx中使用域名，一定要DNS能解析到的，改本地HOST 或者 bond

另外就是BGP宣告VIP这点

### 七、网络的一些基础知识

1、HTTP的响应码

400是bad request，对应一些格式错误，如application/x-www-form-urlencoded使用上的问题
401是认证问题

2、内网的网段

（A类地址的网络号字段占1个字节，只有7位可用（该字段的第一位固定为0，作为IP地址的类别）），网络号7位，主机号24位

1.0.0.0 到 127.255.255.255  通常分配给拥有大量主机的网络（如主干网）  网络数128  每个网络主机数16,777,214  总机器数2,818,571,852

（B类地址的网络号占2个字节，只有14位可用(该字段的前两位固定位10，作为IP地址的类别)），网络号14位，主机号16位

128.0.0.0 到 191.255.255.255  适用于结点比较多的网络（如区域网） 网络数16,384  每个网络主机数65,534       总机器数1,073,709,056

（C类地址的网络号字段占有3个字节，只有21位可用(该字段的前三位固定位110，作为IP地址的类别)），网络号21位，主机号8位

192.0.0.0 到 223.255.255.255  适用于结点比较少的网络（如校园网） 网络数2,097,152  每个网络主机数254       总机器数532,676,608

（D类）

224.0.0.0 到 239.255.255.255

（E类）

240.0.0.0 到 247.255.255.255

内网地址分为A，B和C类（保留的私有IP地址空间）/ 也就是从上面的范围内取值
以下这些地址都属于内网
A类地址范围：10.0.0.0 - 10.255.255.255  
B类地址范围：172.16.0.0 - 172.31.255.255  
C类地址范围：192.168.0.0 - 192.168.255.255  
除了以上的地址和一些比较特殊的地址如127.0.0.1, 169.254.0.0/16等，其他的都属于公网地址

查看IP地址的前几位来确定地址所属的类别！！！！（掩码也就能从Ip地址看出来了）（就是A类开头0，B类开头10，C类开头110，就算是无类别域间路由，这个规则还是不变的）

IP地址是以网络号和主机号来表示网络上的主机的，只有在一个网络号下的计算机之间才能“直接”互通，不同网络号的计算机要通过网关才能互通。将一个大的网络划分成几个较小的网络，而每一个网络都有其自己的子网地址，划分子网的意义

1.减少广播(广播源发送广播地址，整个网络中所有主机均可以收到，但只有目的主机会做出反应)所带来的负面影响。比如：每个A类网络可以有16777214台主机，它们处于同一广播域，那广播将耗时耗流。

2.节约ip地址。比如：有四个机房，每个机房25台机器，需要给这些机器配置IP地址和子网掩码。如果采用4个C类地址段，每个机房一个，然后在一一配置，一共浪费了（254-25）*4=916个IP地址。

通过子网掩码来划分。划分后ip是三层结构。即ip=网络号+子网号+子网主机号；也就是说ip地址在划分子网后，以前的主机号位置的一部分给了子网号，余下的是子网主机号

子网掩码是一个32位地址，通过子网掩码，可以指出一个IP地址中的哪些位对应于网络地址（包括子网地址）、哪些位对应于主机地址。
比如：ip为192.168.1.0，子网掩码为255.255.255.128，由ip知道这是c类网络，c类子网掩码默认为255.255.255.0.
255.255.255.128和默认掩码比多了个128，128二进制代表的八位为10000000；只有1是起作用的，即192.168.1.0的主机号的第一位用来划分子网号，剩下七位作为子网主机号

对于 无类别域间路由选择（CIDR，就叫超网supernetting） 192.168.0.0/21，这是个C类地址（直观上），C类对应的CIDR默认是/24，但是这里是21，所以是一个超网（CIDR消除了传统的A类、B类和C类地址以及划分子网的概念）

不是任何连续的网段都能合并

子网掩码往左移动相应位数后，网络部分保持相同才能合并。！！

判断连续的2个网段是否能够合并，只要第一个网络号能被2整除，就能够通过左移1位子网掩码合并。

判断连续的4个网段是否能够合并，只要第一个网络号能被4整除，就能够通过左移2位子网掩码合并。

子网掩码左移1位能够将能够合并两个网段，左移2位，能够合并四个网段，左移3位，能够合并8个网段

192.168.0.0/24
192.168.1.0/24    192.168.0.0/23
192.168.2.0/24
192.168.3.0/24    192.168.2.0/23   192.168.0.0/22
192.168.4.0/24
192.168.5.0/24    192.168.4.0/23
192.168.6.0/24
192.168.7.0/24    192.168.6.0/23   192.168.4.0/22    192.168.0.0/21

提前说下，为什么有CIDR，子网划分将一个单一的IP地址划分成多个子网，以延缓大型网络地址（主要是B类）的分配速度 [2]  。子网划分从20世纪80年代提出以后的确起到了这个作用。但是到了20世纪90年代，子网划分也就无法阻止B类网络地址最后耗尽的趋势。原因很简单，B类地址只有一万六千多个（就是网络数目！！）。而人们在为中等大小的网络申请地址时，更倾向于使用B类地址（每个网络号下面65,534主机），并在其上进行子网划分，以避免由于使用多个C类地址给网络配置和管理带来的不便，因此，B类地址分配的速度很快，而C类地址的分配速度则慢很多。为了解决B类地址空间紧张的问题，并充分利用C类地址空间（C类网络的数量有2百多万个），人们又提出了超网技术

超网的功能是将多个连续的C类的网络地址聚合起来映射到一个物理网络上。这样，这个物理网络就可以使用这个聚合起来的C类地址的共同地址前缀作为其网络号。超网的优点是可以充分利用C类网络空间资源。在多数情况下，使用超网地址分配乐意使分配的网络空间与实际所需的结点数量相匹配，因而提高了地址空间的利用率。例如，一个4000个结点的物理网络，分配一个B类地址显然是浪费，但C类地址又太小，那么我们可以为该物理网络分配一个由16个连续C类网络构成的地址空间块！！！！（注意，这就是意义！！）

超网方式也带来了新的问题：路由表规模的增长。路由表规模与网络数量成正比。一个物理网络对应多个C类网络地址，使得该网络在路由表中对应于多个C类的前缀表项，使路由表过于庞大。路由协议为交换路由信息而带来的开销也急剧增加。这个问题可采用无类型域间路由就（CIDR，Class Inter-Domain-Routing）技术来解决。尽管一个物理网络在路由表中对应多个表项，但所有表项必然指向同一个下一跳地址，因此有可能对表项进行聚合。CIDR技术可以把路由表中连续的C类网络地址块聚合的C类网络地址必须是连续的，且地址块的数量为2的幂。聚合以后的CIDR地址块的网络前缀的长度。显然，子网掩码的长度将小于24（C类网络的掩码长度）。与子网选路中采用的表示形式一样，CIDR定义得地址快也统一表示成“网络前缀/子网掩码位数”的形式。

练习一下：

（1）由2048个C类网络组成，从192.24.0.0到192.31.255.0，哪个掩码可表示此地址范围？

首先为啥这个是2048个C类呢，是因为 (31-24+1) * 256 = 2048

2048 = 2的11次方，要往前11位，那么掩码13位

（2）反过来，下方的案例，206.0.68.0/22，往后推一位，划分出两个子网，第一个是206.0.68.0/23，但是第二个就是206.0.70.0/23，记住增加的网络位置为1，加上，那么两个网络段的起始结束地址就有了

3、超网和子网

子网和超网的解析

[参考](https://blog.csdn.net/qq_41871202/article/details/118465323)


判断一个网段是子网还是超网

a)通过左移子网掩码合并多个网段，右移子网掩码将一个网段划分成多个子网，使得IP地址打破了传统的A类、B类、C类的界限。

b)判断一个网段到底是子网还是超网，就要看该网段是A类网络、还是B类网络、还是C类网络，默认A类子网掩码/8，B类子网掩码是/16，C类子网掩码是/24。

c)如果该网段的子网掩码比默认子网掩码长，就是子网，如果该网段的子网掩码比默认子网掩码短，则是超网。

注意可以根据2去判断是哪类地址，A还是B还是C，然后比默认长的就是子网，比默认短的就是超网

[参考](http://t.zoukankan.com/FengGeBlog-p-9829912.html)

CIDR概述

英文：Classless Inter-Domain Routing，中文是：无分类域间路由选择。一般叫做无分类编址。

设计目的：解决路由表项目过多过大的问题。

表示法：{<网络前缀>，<主机号>} / 网络前缀所占位数

CIDR表示法给出任何一个IP地址，就相当于给出了一个CIDR地址块。例如这个IP：128.14.35.7/20

　　128.14.35.7/20：00000000 00001110 00100011 00000111

　　我们可以看出来前20位是网络号，后12位是主机号，因此我们还可以计算出这个CIDR地址块的最小地址和最大地址：

　　最小地址：128.14.32.0  = 10000000  00001110  00100000  00000000

　　最大地址：128.14.47.255 = 10000000  00001110  00101111 11111111

　　子网掩码：255.255.240.0 = 11111111  11111111  11110000  00000000

　　因此这个CIDR地址块有（47-32+1）*256=4096个地址，包含全0和全1.

CIDR子网划分

CIDR子网划分与我们之前学习的子网划分方式不同：比如网络号向主机号借走2位时可以划分成4个子网，不用减2（这边应该是说每个子网内的ip个数恰头去尾 减去2）。

例子：某个机构拥有一个大的CIDR地址块，即206.0.64.0/18，（看着不是C类嘛，超网？）现在某个高校需要申请一个较大的CIDR地址块以供学校使用，学校内部又分为4个系，由于每个系的人数不一样，所以要给人数较多的系分配较多的IP地址，人数较少的系分配较少的IP地址，现在采用以下的分配方案：

机构分配给该高校一个CIDR地址块：206.0.68.0/22，然后该高校内部的分配方案如下：

    一系：206.0.68.0/23，一系内部又分为206.0.68.0/25、206.0.68.128/25、206.0.69.0/25和206.0.69.128/25四个子网。
    二系：206.0.70.0/24，二系内部又分为206.0.70.0/26、206.0.70.64/26、206.0.70.128/26和206.0.70.192/26四个子网。
    三系：206.0.71.0/25，三系内部又分为206.0.71.0/26和206.0.71.64/26两个子网。
    四系：206.0.71.128/25，四系内部又分为206.0.71.128/26和206.0.71.192/26两个子网。

    请分析以上方案划分的具体细节。

    第一，这个机构拥有的地址块是206.0.64.0/18 =206.0.0100 0000.0000 0000/18，网络前缀是18位，所以其

    最小地址是：206.0.64.0/18       = 206.0.0100 0000.0000 0000/18
    最大地址是：206.0.127.255/18 = 206.0.0111 1111.1111 1111/18
    子网掩码是：255.255.192.0/18 = 1111 1111.1111 1111.1100 0000.0000 0000/18
    拥有的地址数：(127-64+1)*(255-0+1)=16384

    然后，我们来看一下这个机构给该高校分配的CIDR地址块，即206.0.68.0/22，由此可以看出来网络前缀由18增加到了22，所以该机构相当于将其CIDR地址块划分成了16个子块即子网，然后给该高校了第二个子网，即206.0.0100 0100.0/22，黑色加粗的部分是原来的网络前缀，后面红色部分类似于前面介绍的子网号，由于是4位，所以可以从0000~1111，共16个子网，0001自然就是第二个子网。

    第二，既然高校拥有了机构的第二个子网的CIDR地址块206.0.68.0/22 = 206.0.0100 0100.0/22，其网络前缀是22位，所以其

    最小地址是：206.0.68.0/22       = 206.0.0100 0100.0000 0000/22
    最大地址是：206.0.71.255/22   = 206.0.0100 0111.1111 1111/22
    子网掩码是：255.255.252.0/22 = 1111 1111.1111 1111.1111 1100.0000 0000/22
    拥有的地址数：(71-68+1)*(255-0+1)=1024

    然后该高校内部又对这个CIDR地址块进行了划分，进一步得到了高校内部的子网，紧接着我们来看看一系的CIDR地址块是怎么得到的。

    第三，一系的CIDR地址块是206.0.68.0/23，可以看出来其网络前缀相对于高校的CIDR地址块来说增加了1位，说明高校首先将其CIDR地址块划分成了2个子网，其中一个给了一系。那么这两个子网分别是：一系的：206.0.68.0/23 = 206.0.0100 0100.0/23和剩余的（记为余1）：206.0.70.0/23 =206.0.0100 0110.0/23，注意其中的红色部分就是新增的这一位，用来标志两个子网。

    那么，一系的
    最小地址是：206.0.68.0/23       = 206.0.0100 0100.0000 0000/23
    最大地址是：206.0.69.255/23   = 206.0.0100 0101.1111 1111/23
    子网掩码是：255.255.254.0/23 = 1111 1111.1111 1111.1111 1110.0000 0000/23
    拥有的地址数：(69-68+1)*(255-0+1)=512

    余1的
    最小地址是：206.0.70.0/23       = 206.0.0100 0110.0000 0000/23
    最大地址是：206.0.71.255/23   = 206.0.0100 0111.1111 1111/23
    子网掩码是：255.255.254.0/23 = 1111 1111.1111 1111.1111 1110.0000 0000/23
    拥有的地址数：(71-70+1)*(255-0+1)=512

    现在，一系的CIDR地址块已经很明确，然后一系内部又进行了划分，即又分为206.0.68.0/25、206.0.68.128/25、206.0.69.0/25和206.0.69.128/25四个子网，网络前缀从23位变成了25位，相当于占用了主机号两位，所以可以划分为4个子网，分别对应00、01、10、11这四个子网，这四个子网的最小地址、最大地址以及子网掩码和拥有的地址数按照上述的方法就可以得到。

    第四，一系明确以后，就要考虑其他系的划分，可以看到二系分配到的CIDR地址块是206.0.70.0/24，可以看出来其网络前缀相对于余1的CIDR地址块来说增加了1位，说明余1的CIDR地址块被划分成了2个子网，其中一个给了二系。那么这两个子网分别是：二系的：206.0.70.0/24 = 206.0.0100 0110.0/24和剩余的（记为余2）：206.0.71.0/24 =206.0.0100 0111.0/24，注意其中的红色部分就是新增的这一位，用来标志两个子网。

    那么，二系的
    最小地址是：206.0.70.0/24       = 206.0.0100 0110.0000 0000/24
    最大地址是：206.0.70.255/24   = 206.0.0100 0110.1111 1111/24
    子网掩码是：255.255.255.0/24 = 1111 1111.1111 1111.1111 1111.0000 0000/24
    拥有的地址数：(70-70+1)*(255-0+1)=256

    余2的
    最小地址是：206.0.71.0/24       = 206.0.0100 0111.0000 0000/24
    最大地址是：206.0.71.255/24   = 206.0.0100 0111.1111 1111/24
    子网掩码是：255.255.255.0/24 = 1111 1111.1111 1111.1111 1111.0000 0000/24
    拥有的地址数：(70-70+1)*(255-0+1)=256

    现在，二系的CIDR地址块已经很明确，然后二系内部又进行了划分，即又分为206.0.70.0/26、206.0.70.64/26、206.0.70.128/26和206.0.70.192/26四个子网，网络前缀从24位变成了26位，相当于占用了主机号两位，所以可以划分为4个子网，分别对应00、01、10、11这四个子网，这四个子网的最小地址、最大地址以及子网掩码和拥有的地址数按照上述的方法就可以得到。

    第五，二系明确以后，就要考虑其他系的划分，可以看到三系分配到的CIDR地址块是206.0.71.0/25，而四系分配到的CIDR地址块是206.0.71.128/25，可以看出来其网络前缀相对于余2的CIDR地址块来说增加了1位，说明余2的CIDR地址块被划分成了2个子网，其中一个给了三系，另外一个给了四系。那么这两个子网分别是：三系的：206.0.71.0/25 = 206.0.71.0000 0000/25和四系的：206.0.71.128/25 = 206.0.71.1000 0000/25，注意其中的红色部分就是新增的这一位，用来标志两个子网。

    那么，三系的
    最小地址是：206.0.71.0/25       = 206.0.0100 0100.0000 0000/25
    最大地址是：206.0.71.127/25   = 206.0.0100 0100.0111 1111/25
    子网掩码是：255.255.255.128/25 = 1111 1111.1111 1111.1111 1111.1000 0000/25
    拥有的地址数：(71-71+1)*(127-0+1)=128


    四系的
    最小地址是：206.0.71.128/25   = 206.0.0100 0111.1000 0000/25
    最大地址是：206.0.71.255/25   = 206.0.0100 0111.1111 1111/25
    子网掩码是：255.255.255.128/25 = 1111 1111.1111 1111.1111 1111.1000 0000/25
    拥有的地址数：(71-71+1)*(255-128+1)=128

    现在，三系和四系的CIDR地址块已经很明确，到目前为止，该高校已经将所有的CIDR地址块分配给了四个系，一系有512个地址，二系有256个地址，三系和四系各有128个地址。然后三系内部又进行了划分，即又分为206.0.71.0/26和206.0.71.64/26两个子网，网络前缀从25位变成了26位，相当于占用了主机号一位，所以可以划分为2个子网，分别对应0、1这两个子网，同时，四系内部也又进行了划分，即又分为206.0.71.128/26和206.0.71.192/26两个子网，网络前缀从25位变成了26位，相当于占用了主机号一位，所以可以划分为2个子网，分别对应0、1这两个子网，三系和四系各自的两个子网的最小地址、最大地址以及子网掩码和拥有的地址数按照上述的方法就可以得到，这个比较简单，建议大家可以自己手动计算一下，正好看看自己掌握了多少，这里就不再给出这些子网的细节。

上面这个例子举的还是蛮好的

最后我们给出本题的图画，画出来类似一个二叉树

10.60.117.207属于哪个cidr，10.60.116.0/22在这个里面，看这个cidr的划分，还是要基于ip划分范围的，是10.60.116.255 - 10.60.119.255

128  64  32  16  8  4  2  1

128.14.35.7/20 范围在128.14.32.0 - 128.14.47.255  一

128.14.35.7/23 范围在128.14.34.0 - 128.14.35.255  二 // 进位的算法有点问题，minIp会是一样，128.14.32.1 在 一 里面 但不在 二 里面，但匹配 二跟一的minIp是一样的，都是按照128.14.35.7算的

// 总结1 cidr的计算法，这个ip肯定是在ipcidr地址段内的
// 总结2 按照正常的步骤算ip地址范围

4、三次握手 和 四次挥手 和 传输数据

其实要结合抓包看一下的，三次握手和四次握手是比较有规律的，对应的Flag就是发对应的seq和ack

三次握手：

第一步 SYN=1，seq=x
第二步 SYN=1，ACK=1，seq=y，ack=x+1
第三步 ACK=1，ack=y+1

数据传输：

比方说redis发送 ping 返回pong

```html

10:05:19.769088 IP (tos 0x10, ttl 64, id 36785, offset 0, flags [DF], proto TCP (6), length 58)
    10.128.191.182.50854 > 10.4.73.209.6379: Flags [P.], cksum 0x1e38 (incorrect -> 0x8fe4), seq 1931115685:1931115691, ack 297068310, win 229, options [nop,nop,TS val 518699424 ecr 3483593652], length 6: RESP "ping"
10:05:19.769222 IP (tos 0x0, ttl 58, id 63643, offset 0, flags [DF], proto TCP (6), length 52)
    10.4.73.209.6379 > 10.128.191.182.50854: Flags [.], cksum 0x3528 (correct), seq 297068310, ack 1931115691, win 510, options [nop,nop,TS val 3483611450 ecr 518699424], length 0
10:05:19.769273 IP (tos 0x0, ttl 58, id 63644, offset 0, flags [DF], proto TCP (6), length 59)
    10.4.73.209.6379 > 10.128.191.182.50854: Flags [P.], cksum 0x696d (correct), seq 297068310:297068317, ack 1931115691, win 510, options [nop,nop,TS val 3483611450 ecr 518699424], length 7: RESP "PONG"
10:05:19.769279 IP (tos 0x10, ttl 64, id 36786, offset 0, flags [DF], proto TCP (6), length 52)
    10.128.191.182.50854 > 10.4.73.209.6379: Flags [.], cksum 0x1e32 (incorrect -> 0x3639), seq 1931115691, ack 297068317, win 229, options [nop,nop,TS val 518699425 ecr 3483611450], length 0

```

第一次Flags [P.]，seq和ack都有，发送的是ping

第二次Flags [.]，seq和ack也都有，是对ping的ack

第三次Flags [P.]，seq和ack都有，发送的是pong

第四次Flags [.]，seq和ack也都有，是对pong的ack

ack不增长seq的数字


四次挥手：

？？？
第一步 FIN=1，seq=u
第二步 ACK=1，seq=v，ack=u+1
第三步 FIN=1，ACK=1，seq=w，ack=u+1
第四步 ACK=1，seq=u+1，ack=w+1

服务端发起的话：

第一步 FIN=1，ACK=1，seq=u，ack=v  服务端发
第二步 ACK=1，ack=u+1
第三步 FIN=1，ACK=1，seq=v，ack=u+1
第四步 ACK=1，ack=v+1

挥手的响应ack也是需要+1的

5、队头阻塞

通常我们提到队头阻塞，指的可能是TCP协议中的队头阻塞，但是HTTP1.1中也有一个类似TCP队头阻塞的问题

TCP队头阻塞：队头阻塞（head-of-line blocking）发生在一个TCP分节丢失，导致其后续分节不按序到达接收端的时候。该后续分节将被接收端一直保持直到丢失的第一个分节被发送端重传并到达接收端为止。该后续分节的延迟递送确保接收应用进程能够按照发送端的发送顺序接收数据。这种为了达到完全有序而引入的延迟机制非常有用，但也有不利之处。
假设在单个TCP连接上发送语义独立的消息，比如说服务器可能发送3幅不同的图像供Web浏览器显示。为了营造这几幅图像在用户屏幕上并行显示的效果，服务器先发送第一幅图像的一个断片，再发送第二幅图像的一个断片，然后再发送第三幅图像的一个断片；服务器重复这个过程，直到这3幅图像全部成功地发送到浏览器为止。
要是第一幅图像的某个断片内容的TCP分节丢失了，客户端将保持已到达的不按序的所有数据，直到丢失的分节重传成功。这样不仅延缓了第一幅图像数据的递送，也延缓了第二幅和第三幅图像数据的递送。

HTTP队头阻塞：上面用浏览器请求图片资源举例子，但实际上HTTP自身也有类似TCP队头阻塞的情况。要介绍HTTP队头阻塞，就需要先讲讲HTTP的管道化（pipelining）。（管道化pipelining）HTTP1.1 允许在持久连接上可选的使用请求管道。这是相对于keep-alive连接的又一性能优化。在相应到达之前，可以将多条请求放入队列，当第一条请求发往服务器的时候，第二第三条请求也可以开始发送了，在高延时网络条件下，这样做可以降低网络的环回时间，提高性能。

前面提到HTTP管道化要求服务端必须按照请求发送的顺序返回响应，那如果一个响应返回延迟了，那么其后续的响应都会被延迟，直到队头的响应送达。

如何解决HTTP队头阻塞：对于HTTP1.1中管道化导致的请求/响应级别的队头阻塞，可以使用HTTP2解决。HTTP2不使用管道化的方式，而是引入了帧、消息和数据流等概念，每个请求/响应被称为消息，每个消息都被拆分成若干个帧进行传输，每个帧都分配一个序号。每个帧在传输是属于一个数据流，而一个连接上可以存在多个流，各个帧在流和连接上独立传输，到达之后在组装成消息，这样就避免了请求/响应阻塞。
当然，即使使用HTTP2，如果HTTP2底层使用的是TCP协议，仍可能出现TCP队头阻塞。

如何解决TCP队头阻塞：TCP中的队头阻塞的产生是由TCP自身的实现机制决定的，无法避免。想要在应用程序当中避免TCP队头阻塞带来的影响，只有舍弃TCP协议。
比如google推出的quic协议，在某种程度上可以说避免了TCP中的队头阻塞，因为它根本不使用TCP协议，而是在UDP协议的基础上实现了可靠传输。而UDP是面向数据报的协议，数据报之间不会有阻塞约束。
此外还有一个SCTP（流控制传输协议），它是和TCP、UDP在同一层次的传输协议。SCTP的多流特性也可以尽可能的避免队头阻塞的情况。


https://juejin.cn/post/6844903853985366023


6、DNS

DNS流程

DNS在本及有两种缓存，一个是浏览器的，一个是系统的

先浏览器，再系统，再发起dns query

浏览器，google举例，chrome://net-internals/#dns，发现没有东西，原来方式废除了，需要手动去开启记录到本地硬盘

chrome://net-internals/#events 后可以导出日志，然后在https://netlog-viewer.appspot.com再导入日志查看，左边栏选择dns的

google浏览器缓存是60s，最大并发数是6个per域名（注意是每个域名），看下浏览器中的connectionId，其实多个标签下是共用最大并发连接的connectionId的，不同域名下不同，强刷后，Id变化

windows DNS缓存的默认值是 MaxCacheTTL，见这里，它的默认值是86400s，也就是一天。它是TTLu 这篇文章列出了一些浏览器的DNS缓存时间。

浏览器DNS缓存的时间跟ttl值无关，每种浏览器都使用一个固定值

用dig查询解析结果

ANSWER SECTION: //得到的问题的答案(回应部分)
www.ihoney.net.cn. 600 IN CNAME 9a8044ec.ihoney.net.cn.cname.jsd.cc.
9a8044ec.ihoney.net.cn.cname.jsd.cc. 60 IN A 59.56.19.31
9a8044ec.ihoney.net.cn.cname.jsd.cc. 60 IN A 183.131.214.50
第一列：NAME 查询的域名
第二列：TTL 缓存时间，表示缓存域名服务器可以在缓存中保存多少秒该记录
第三列：class 要查询信息的类别，IN代表类别为internet
第四列：TYPE 要查询的记录类型
第五列：VALUE 域名对应的CNAME的值和A记录的值

AUTHORITY SECTION: //负责解析的权威ns服务器(权威域名部分)
jsd.cc. 3363 IN NS dns2.cloudcdns.com.
jsd.cc. 3363 IN NS dns1.cloudcdns.com.
第一列：NAME 域名
第二列：TTL 缓存时间
第三列：class 要查询信息的类别，IN代表类别为internet
第四列：TYPE 要查询的记录类型
第五列：VALUE 域名对应的权威域名解析服务器

dns相关

https://www.ruanyifeng.com/blog/2016/06/dns.html


6、TCP的几种状态

CLOSED: 这个没什么好说的了，表示初始状态。

LISTEN（服务器）: 这个也是非常容易理解的一个状态，表示服务器端的某个SOCKET处于监听状态，可以接受连接了。

YN_RCVD（服务器）: 这个状态表示接受到了SYN报文，在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，很短暂，基本上用netstat你是很难看到这种状态的，除非你特意写了一个客户端测试程序，故意将三次TCP握手过程中最后一个ACK报文不予发送。因此这种状态时，当收到客户端的ACK报文后，它会进入到ESTABLISHED状态。

SYN_SENT: 这个状态与SYN_RCVD遥想呼应，当客户端SOCKET执行CONNECT连接时，它首先发送SYN报文，因此也随即它会进入到了SYN_SENT状态，并等待服务端的发送三次握手中的第2个报文。SYN_SENT状态表示客户端已发送SYN报文。

ESTABLISHED：这个容易理解了，表示连接已经建立了。

FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。

FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你，稍后再关闭连接。

TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。

　　注:MSL(最大分段生存期)指明TCP报文在Internet上最长生存时间,每个具体的TCP实现都必须选择一个确定的MSL值.RFC 1122建议是2分钟,但BSD传统实现采用了30秒.TIME_WAIT 状态最大保持时间是2 * MSL,也就是1-4分钟.

　　结论：在TIME_WAIT下等待2MSL，只是为了尽最大努力保证四次握手正常关闭。确保老的报文段在网络中消失，不会影响新建立的连接.


CLOSING: 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送FIN报文后，按理来说是应该先收到（或同时收到）对方的ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什么情况下会出现此种情况呢？其实细想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。

CLOSE_WAIT: 这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。

LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。
