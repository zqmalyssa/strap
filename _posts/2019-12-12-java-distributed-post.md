---
layout: post
title: JAVA分布式
author-id: "zqmalyssa"
tags: [distribute, code, java]
---

JAVA分布式应用，这块单独作为分布式的内容总结一下

#### 分布式JAVA应用

大型应用通常会拆分为多个子系统来实现，对于JAVA来说，这些系统可能部署在同一台机器的多个不同JVM中，也可能部署在不同的机器上，但这些子系统又不是完全独立的，要**相互通信**共同来实现业务功能，对于这类java应用，我们称为分布式JAVA应用。两种实现方式

1. 基于消息方式实现系统间的通信
	- BIO，NIO，AIO，BIO发起IO的读写操作时，全是阻塞模式，NIO是非阻塞，是基于事件驱动的思想，AIO是异步的
	- JDK7目前只支持BIO和NIO
	- java自带的这些消息通信方式还是比较繁琐的，开源业界有像Mina这样的系统间通信框架，Mina是Apache的顶级项目，基于java nio，同时支持tcp和udp，屏蔽了nio的复杂性，性能上又做了不少优化

2. 基于远程调用方式实现系统间的通信
	- 主要是RMI和WebService来实现
	- 系统内的通信，如1中说的是A a = new AImpl(); a.call();的方式，但变成分布式后，就无法用以上的方式直接调用了，因为在调用端并不会有AImpl这个类，基于1中的方式就比较晦涩了，众多的开源框架中如Spring RMI和CXF，就是基于远程的调用方式实现系统间的通信
	- RMI，在远程调用中，客户端仅有服务器端提供的接口，通过此接口实现对远程服务器端的调用
	- Webservice跨语言的系统间标准协议，HTTP方式访问WSDL，采用WSDL描述，调用端和服务端通过SOAP来进行交互
	- 开源框架中的spring RMI，实现IOC帮你管理服务器，客户端，而CXF是Apache的顶级项目，也是目前Java社区中用来实现WebService流行的开源框架，CXF在服务器端没有过多的封装，只是提供了一个JaxWsServerFactoryBean类，从而可以在WebService被调用时增加一些拦截器的处理，客户端CXF增加了封装，以便直接**以接口的方式**调用远程WebService。类似CXF的开源框架还不少，还有Axis，除了对Java WebService使用方法进行封装外，提升了易用性，还增加了多种协议来调用WebService


系统大了后，业务多元化，访问也上涨，开发人员每访问一个共用业务逻辑系统或拆分出来的系统后，都可能要学习不同的交互方式，同时也会造成各个开发团队重复造轮子，提供不同交互方式用的框架，这对于应用的性能，可用性而言都带来了极大挑战，对于上面的问题，解决的一个办法就是统一交互方式，SOA就是实现这种方式的首选

SOA全称是面向服务架构，它强调系统之间以标准的服务方式进行交互，各系统可采用不同的语言、不同的框架实现，交互则全部通过服务的方式进行。基于服务会有如下挑战

1. 服务的多级调用带来演示，A调B，B调C
2. 调试，定位难，一个一个甩锅
3. 每个子服务都要考虑安全/监测
4. 现有应用移植，比较麻烦
5. QoS的支持，保证QoS，例如流量控制、机器资源分配
6. 高可用和高度可伸缩性
7. 多版本和依赖管理

实现SOA，可参考的标准或概念有SCA、ESB，同时业界也有一些实现了SCA和ESB的框架

SCA可以在不侵入系统的状况下以多种方式引用SCA服务，并将其注入需要引用服务的系统中，这些系统同样可以以Java、Spring或C++等各种方式实现，SCA标准默认提供的通信方式的SCA、WebService、JMS三种。SCA在调用跟踪上没有明确的定义，只能自行实现，依赖管理方面同样没有明确的定义，实现困难，高性能及高可用也支持不好

ESB不像SCA是多个厂商指定标准，它更像是一个概念，核心思想是基于消息中间件来实现系统间的交互，系统交互的中间场所称为总线，系统间交互的数据格式采用统一的消息格式，由总线完成消息的转化和路由，发送到对应的目标应用，通常ESB具有5个要素

1. 标准的消息通信格式
2. 消息路由，更多的还能完成消息编排
3. 支持多种的消息交互类型，支持请求/响应，发布/订阅，请求/响应更加方便的实现同步请求，发布/订阅则更加方便实现异步的消息广播
4. 支持多种网络协议TCP，HTTP
5. 支持多种数据格式并能进行相互转换

SCA的实现框架有Tuscany，IBM和Bea贡献给Apache的，ESB有Mule的实现，综上，SCA对于服务的统一交互支持的很好，ESB更适用于需要解耦的方式服务交互及复杂的多服务交互场景，但实现大型SOA平台时，仍需要自行扩展实现的地方很多，需要有下列完备的东西

1. 支撑集群环境，支撑大的访问量，软件负载均衡
2. 完善的服务治理，目的是保证服务能够稳定、高性能运转，之前时候的依赖管理也是属于服务治理的一项，服务运行状况的监测，服务的安全机制，服务的流量限制，服务故障根源的推测，服务可用性的保障都属于服务治理范畴，紧靠SOA平台很难做到，还需要系统架构的配合
3. 服务QoS的支持，A服务QoS每秒支撑5000请求，响应事件95%需要在1秒以内，SOA要能收集目前服务的运行状况来合理的分配机器资源，要做到这点难度非常高


数据中单Master和多Master的时候，如果是多Master，就要考虑这多个写入点了，通常采取两阶段提交、三阶段提交或者基于Paxos的方式来保持多master数据的一致性

2PC 实现起来简单，但是master上都要冻结资源，而且一旦有一个master出现问题就要全部回滚

3PC 在二阶段又增加了preCommit，当所有master收到preCommit后，并不执行动作，直到收到commit或超过一定时间后才完成操作

Paxos 不要求所有的master都反馈成功，只需要大多数反馈成功就行了


### 分布式补充

EJB，LAMP等开发模式是垂直型业务的（也包括MVC，这里不包括思想），可能部个代码要10多分钟，后面进化到使用服务，有RPC的概念

1. RPC可以自己实现，用的jdk的动态代理
2. 主流框架有Apache Thrift，Avro-RPC，Hessian，gRPC
3. Thrift支持如下通信，阻塞式TSocket，非阻塞式TFreamedTransport（类似于NIO）

这其实就类似于上文说的[基于消息方式实现系统间的通信]，RPC的框架会遇到如下问题：

1. 服务越来越多时，服务URL配置管理变得非常困难，F5等硬件的单点压力很大，需要一个服务注册中心，动态的注册和发现服务
2. 服务间的依赖变得错综复杂，需要一个分布式消息跟踪系统可视化展示服务调用链
3. 服务容量问题，需要多少机器支撑
4. 服务上线容易下线难

服务化后，随之而来的就是服务治理，上面的问题就需要服务框架和服务治理来完成，单凭RPC没有很好的效果，这就引出SOA的概念，粗粒度，松耦合的以服务为中心的架构，接口之间通过定义明确的协议和接口进行通信，一般的SOA的原则如下

1. 服务可复用，
2. 服用共享一个标准契约
3. 服务是松耦合的
4. 服务是底层逻辑的抽象
5. 服务是可组合，可编排的，多个服务可能被编排组合成一个新的服务，这允许不同逻辑抽象的自由组合，促进服务的复用
6. 服务是自治的，逻辑由服务所控制，并位于一个清晰的边界内，服务已经在边界内被控制，不依赖于其他服务
7. 服务是无状态的，状态管理移至他处
8. 服务是可以被自动发现的

应用服务化后给系统运维又带来了很大挑战

1. 分布式框架下的服务调用性能
2. 服务化加厚如何支持线性扩展
3. 如何实现高效、实时的服务多维度监控
4. 大规模的故障快速定位
5. 海量日志的在线检索
6. 服务的流控制、超时控制、服务升降级
7. 服务的划分原则

SOA中服务治理是关键，服务治理主要包括：

1. 服务定义
2. 服务生命周期管理
3. 服务版本治理
4. 服务注册中心，发布/订阅服务
5. 服务监控
6. 运行期服务质量保障
7. 快速的故障定界定位手段
8. 服务安全

微服务架构其实就是一种服务化架构风格，通过将功能分散到各个离散的服务中以实现对解决方案的解耦，敏捷开发，快速交付等也促进了微服务的发展，CICD，DevOps流行促进了小团队独立运作和交付，微服务有以下特征：

1. 原子服务
2. 高密度部署，可以再一台服务器上部署多个服务实例进程
3. 敏捷交付
4. 微自治

微服务面向SOA主要是要做什么呢

1. 拆分粒度更小，SOA只是解决异构应用的服务化，微服务需要独立的原子服务
2. 服务依赖的话想要去除服务间依赖
3. 服务规模，膨胀，因为小
4. 架构质量会受到影响，要保证高性能，低时延，更好的分布式微服务框架
5. 服务治理方面，运行的微服务治理
6. 敏捷交付，实现真正DevOPS

其实就是量变引起了质变，考虑的东西更多，更细，服务化改造需要用到的就是分布式服务框架

开源的主要有阿里巴巴的Dubbo，以及当当网基于Dubbo增强的DubboX，非开源的有淘宝的HSF，亚马逊的Coral Service，华为DSF

Dubbo的内容，Provider/Container，Registry，Consumer，Dubbo的主要质量属性是

1. 连通性，注册中心，服务提供者，服务消费者，监控中心之间的连通性
2. 健壮性
3. 伸缩性，
4. 扩展性

除了RPC框架功能，Dubbo还提供了丰富的服务治理功能，各个公司提供的服务框架可能不一样，但是核心功能差异不大，通常抽象成三层

1. RPC层，包括底层通信框架，NIO，公有协议的封装，序列化和反序列化
2. Filter层，服务调用职责链，提供多种服务调用切面共框架自身和使用者扩展，如负载均衡，服务调用性能统计，完成通知机制，失败重发等
3. Service层，主要包括java动态代理，消费者使用，主要用于将服务提供者的接口封装成远程服务调用，java反射，服务提供者使用，向上就是服务接口定义和实现类

从功能角度看，分布式服务框架通常会包含另两个重要功能，服务治理中心和服务注册中心，服务注册中心，业务需求不一样，实现方式不同，HSF使用基于数据库的ConfigServer，Dubbo默认使用的ZooKeeper

服务注册中心负责服务的发布和通知，通常支持对等集群的部署，某个服务注册中心宕机不会导致整个服务中心集群不可用，影响的是新服务的注册和发布，不影响已发布的服务的访问

服务治理中心通常包括服务治理接口和服务治理的Portal，可以对服务的运行状态、历史数据、健康度和调用关系等进行可视化的分析和维护，目标就是要持续优化服务

公共能力如下：

1. 服务订阅发布，发布后由注册中心推送服务地址，消费者不需要配置服务提供者地址，服务地址透明化，服务也可以在线注册和去注册
2. 服务路由，随机路由，粘滞连接等等
3. 集群容错，failover，failback，failfast
4. 服务调用，同步、异步调用，并行调用
5. 多协议，序列化
6. 统一配置，本地配置和运行时可以动态调整的配置（服务注册中心）

服务治理：

1. 服务运行态管控，包括，服务路由，服务限流，服务迁入迁出，服务降级，服务超时控制
2. 服务监控，性能统计，统计报表，告警
3. 服务生命周期管理，上线审批，下线通知，服务灰度发布
4. 故障快速定界定位，分布式日志采集，海量日志在线检索，调用链可视化展示，运行日志故障定位
5. 服务安全，敏感服务的授权策略，链路安全防护


按照上面的三个层次分层讨论，

**RPC层**

通信框架：

1. 采用长连接进行内部通信，节省资源，要知道远程通信是常态
2. BIO中是Socket和ServerSocket，而NIO中是SocketChannel和ServerSocketChannel，两种不同的套接字通道实现，这两种新增的通道都支持阻塞和非阻塞模式，高负载高并发的应用，用到NIO的非阻塞，NIO是采用的多路复用技术，一个多路复用器selector可以同时轮询多个channel。NIO开发太难，可以用开源框架，就是大名鼎鼎的netty了，netty的优势，API简单，开发门槛低，功能强大，定制能力强，性能高

序列化与反序列化：

1. Java自带的Serializable开发门槛低，使用方便，但由于自身存在很多缺点，不会作为分布式框架的开发方式，它是内部的私有协议，java序列化后的字节数组，别的语言无法进行反序列化，而像Messagepack，PB，Thrift，avro等都支持多种语言
2. 序列化框架的好坏就是对多语言的支持

协议的选择：

模块之间解决公有服务调用问题用公有的协议，如webservice，大家统一标准，而解决内部服务化跨进程通信问题，性能优先，所以像PB等二进制序列化框架，性能会比SOAP的Webservice高一截，SOAP通常是http承载，不支持双向全双工通信，而且一般使用短连接，性能比较差

**filter层**

服务路由：

需要用到服务注册中心（ZooKeeper），服务消费者和提供者需要通过注册中心提供的SDK与注册中心建立链路（ZooKeeper采用长连接），注册中心将变更内容主动推送给服务消费者，消费者根据变更列表，动态刷新本地缓存的服务提供者地址

负载均衡策略，有随机的，轮询的，服务调用时延，一致性hash，粘滞连接（让客户端连接一个服务，除非这个服务down掉），还有一些路由规则的设置

**这边就说下一致性Hash**，在解决分布式系统中负载均衡的问题时候可以使用Hash算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡的作用。但是普通的余数hash（hash(比如用户id)%服务器机器数）算法伸缩性很差，当新增或者下线服务器机器时候，用户id与服务器的映射关系会大量失效（想想hashmap做扩容的时候要重新计算hash）。一致性hash则利用hash环对其进行了改进。

为了能直观的理解一致性hash原理，这里结合一个简单的例子来讲解，假设有4台服务器，地址为ip1,ip2,ip3,ip4。

1、一致性hash是首先计算四个ip地址对应的hash值，hash(ip1),hash(ip2),hash(ip3),hash(ip3)，计算出来的hash值是0~最大正整数之间的一个值，这四个值在一致性hash环上呈现如下图：

![hash_1]({{ "/assets/img/distribution/hash_1.png" | relative_url}})

hash环上顺时针从整数0开始，一直到最大正整数，我们根据四个ip计算的hash值肯定会落到这个hash环上的某一个点，至此我们把服务器的四个ip映射到了一致性hash环，当用户在客户端进行请求时候，首先根据hash(用户id)计算路由规则（hash值），然后看hash值落到了hash环的那个地方，根据hash值在hash环上的位置顺时针找距离最近的ip作为路由ip.

![hash_2]({{ "/assets/img/distribution/hash_2.png" | relative_url}})

如上图可知user1,user2的请求会落到服务器ip2进行处理，User3的请求会落到服务器ip3进行处理，user4的请求会落到服务器ip4进行处理，user5,user6的请求会落到服务器ip1进行处理。

2、下面考虑当ip2的服务器挂了的时候会出现什么情况？当ip2的服务器挂了的时候，一致性hash环大致如下图：

![hash_3]({{ "/assets/img/distribution/hash_3.png" | relative_url}})

根据顺时针规则可知user1,user2的请求会被服务器ip3进行处理，而其它用户的请求对应的处理服务器不变，也就是只有之前被ip2处理的一部分用户的映射关系被破坏了，并且其负责处理的请求被顺时针下一个节点委托处理。

3、下面考虑当新增机器的时候会出现什么情况？当新增一个ip5的服务器后，一致性hash环大致如下图：

![hash_4]({{ "/assets/img/distribution/hash_4.png" | relative_url}})

根据顺时针规则可知之前user5的请求应该被ip5服务器处理，现在被新增的ip5服务器处理，其他用户的请求处理服务器不变，也就是新增的服务器顺时针最近的服务器的一部分请求会被新增的服务器所替代。

一致性hash的特性

1、单调性(Monotonicity)，单调性是指如果已经有一些请求通过哈希分派到了相应的服务器进行处理，又有新的服务器加入到系统中时候，应保证原有的请求可以被映射到原有的或者新的服务器中去，而不会被映射到原来的其它服务器上去。 这个通过上面新增服务器ip5可以证明，新增ip5后，原来被ip1处理的user6现在还是被ip1处理，原来被ip1处理的user5现在被新增的ip5处理。

2、分散性(Spread)：分布式环境中，客户端请求时候可能不知道所有服务器的存在，可能只知道其中一部分服务器，在客户端看来他看到的部分服务器会形成一个完整的hash环。如果多个客户端都把部分服务器作为一个完整hash环，那么可能会导致，同一个用户的请求被路由到不同的服务器进行处理。这种情况显然是应该避免的，因为它不能保证同一个用户的请求落到同一个服务器。所谓分散性是指上述情况发生的严重程度。好的哈希算法应尽量避免尽量降低分散性。 一致性hash具有很低的分散性

3、平衡性(Balance)：平衡性也就是说负载均衡，是指客户端hash后的请求应该能够分散到不同的服务器上去。一致性hash可以做到每个服务器都进行处理请求，但是不能保证每个服务器处理的请求的数量大致相同，如下图

![hash_5]({{ "/assets/img/distribution/hash_5.png" | relative_url}})

服务器ip1,ip2,ip3经过hash后落到了一致性hash环上，从图中hash值分布可知ip1会负责处理大概80%的请求，而ip2和ip3则只会负责处理大概20%的请求，虽然三个机器都在处理请求，但是明显每个机器的负载不均衡，这样称为一致性hash的倾斜，虚拟节点的出现就是为了解决这个问题。

**虚拟节点**

当服务器节点比较少的时候会出现上节所说的一致性hash倾斜的问题，一个解决方法是多加机器，但是加机器是有成本的，那么就加虚拟节点，比如上面三个机器，每个机器引入1个虚拟节点后的一致性hash环的图如下：其中ip1-1是ip1的虚拟节点，ip2-1是ip2的虚拟节点，ip3-1是ip3的虚拟节点。
可知当物理机器数目为M，虚拟节点为N的时候，实际hash环上节点个数为M*N。比如当客户端计算的hash值处于ip2和ip3或者处于ip2-1和ip3-1之间时候使用ip3服务器进行处理。

**均匀一致性hash**

上节我们使用虚拟节点后的图看起来比较均衡，但是如果生成虚拟节点的算法不够好很可能会得到下面的环：可知每个服务节点引入1个虚拟节点后，情况相比没有引入前均衡性有所改善，但是并不均衡。均衡的一致性hash应该是如果服务器有N台，客户端的hash值有M个，那么每个服务器应该处理大概M/N个用户的。也就是每台服务器负载尽量均衡


集群容错：

这边墙裂补充下**幂等性**，

幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品使用约支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条

在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是在响应客户端的时候也有可能出现网络中断或者异常等等。在增删改查4个操作中，尤为注意就是增加或者修改，查询对于结果是不会有改变的，删除只会进行一次，用户多次点击产生的结果一样，修改在大多场景下结果一样，增加在重复提交的场景下会出现

那么如何设计接口才能做到幂等呢？

方法一、单次支付请求，也就是直接支付了，不需要额外的数据库操作了，这个时候发起异步请求创建一个唯一的ticketId，就是门票，这张门票只能使用一次就作废，具体步骤如下：

1、异步请求获取门票

2、调用支付，传入门票

3、根据门票ID查询此次操作是否存在，如果存在则表示该操作已经执行过，直接返回结果；如果不存在，支付扣款，保存结果

4、返回结果到客户端

如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的


方法二、分布式环境下各个服务相互调用

这边就要举例我们的系统了，我们支付的时候先要扣款，然后更新订单，这个地方就涉及到了订单服务以及支付服务了。

用户调用支付，扣款成功后，更新对应订单状态，然后再保存流水。

而在这个地方就没必要使用门票ticketId了，因为会比较闲的麻烦

（支付状态：未支付，已支付）

步骤：

1、查询订单支付状态

2、如果已经支付，直接返回结果

3、如果未支付，则支付扣款并且保存流水

4、返回支付结果

如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的

对于做过支付的朋友，幂等，也可以称之为**冲正**，保证客户端与服务端的交易一致性，避免多次扣款。


出错后，系统自行选择容错策略：

1. Failover，调用失败后，重新选路，查找下一个可用的服务提供者，即返回到了路由的Handler入口
2. Failback，不在重试，将异常给消费者
3. Failcache，失败自动恢复，对时延要求不敏感，比如粉丝积分增长，记录接口日志
4. Failfast，非核心的业务，就只调用一次，失败也不再重试

服务调用：

这里又要补充一下reactor了，reactor线程模型是解决传统的问题，结合IO复用和线程池，可以分成三类：

1、单Reactor单线程模型
2、单Reactor多线程模型
3、多Reactor多线程模型

Reactor的三种线程模型可以用餐厅的接待员和服务员类比

1、单Reactor单线程模型：接待员和服务员是同一个人，一直为顾客服务。客流量较少适合
2、单Reactor多线程模型：一个接待员，多个服务员。客流量大，一个人忙不过来，由专门的接待员在门口接待顾客，然后安排好桌子后，由一个服务员一直服务，一般每个服务员负责一片中的几张桌子
3、多Reactor多线程模型：多个接待员，多个服务员。这种就是客流量太大了，一个接待员忙不过来了

回到正题，NIO只是解决了通信层面的异步问题，跟服务调用的异步没有必然关系，也就是说，即使采用传统的BIO通信，依然可以实现异步服务调用，只不过通信效率和可靠性比较差而已

通过消息队列的方式实现业务层和通信层的分离是比较成熟、典型的做法，现代的RPC框架或者Web服务器很少直接使用业务线程进行网络读写

同步阻塞等待应答并非是唯一的技术选择，我们也可以利用java的Future-Listener机制来实现异步服务调用，从业务角度看，它的效果与同步等待等价，但是从技术层面看，却是个很大的进步，它可以保证业务线程在不同步阻塞的情况下实现同步等待的效果，服务执行效率更高。

说一下服务的调用方式：

1、同步服务调用，最常见也是默认需要实现的方式，客户端发起远程服务调用请求，用户线程完成消息序列化后，将消息投递到通信框架，然后同步阻塞，等待通信线程发送请求并接收到应答之后，唤醒同步等待的用户线程，用户线程获取到应答之后返回

2、异步服务调用，基于JDK的Future机制，可以非常方便的实现异步服务调用，一般使用往往会扩展Future，提供Future-Listener机制，它支持主动获取和被动异步回调通知两种方式，Future-Listener的异步服务调用相比于Future-get模式更好，但是在实际使用中有一定的局限性

3、并行服务调用，比方购买游戏道具，三个鉴权流程可以并行执行，最终执行结果做个join即可，解决串行购买游戏道具效率低的问题，有两个解决策略：异步服务调用和并行服务调用。实现并行服务调用的几种解决方案：一个是JDK7中的fork/join，可以实现子任务的并行执行和结果汇聚，BPM的Parallel Gateway和批量串行服务调用

4、泛化调用，包含两种调用方式，泛化引用和泛化实现，比如实现一个通用的远程服务Mock框架

服务注册中心：

如何有效的管理服务订阅和发布，避免硬编码方式是分布式服务框架需要解决的一个问题，通过将服务统一管理起来，可以有效的优化内部应用对服务发布/使用的流程和管理，主要特点

1、高HA，支持数据持久化，支持集群
2、数据一致性问题，集群所有的客户端应该看到同一份数据，不能出现读或者写数据不一致
3、数据变更主动推送，当注册中心的数据发生变更时，需要能够及时将变化的数据通知给客户端

基于ZooKeeper的服务注册中心设计，ZooKeeper是Hadoop的一个子项目，它主要用来解决分布式应用中经常遇到的一些数据管理问题，如统一命名服务，状态同步服务，集群管理，分布式应用统一配置

ZooKeeper的集群中Server有Leader和Follower，Follower服务client的请求，ZooKeeper集群的管理核心是原子广播。。这个机制保证各个Server之间的数据同步，实现这个机制的协议叫作Zab协议，Zab有两种模式，恢复模式和广播模式

Broadcast模式类似于分布式事务中的两阶段提交，即leader提起一个决议，由follower进行投票，leader对投票结果进行计算决定是否通过该协议，如果通过则执行该决议，否则什么也不做

服务的发布和引用：

服务发布的几种方式，

1、XML配置化方式
	- 服务框架对业务代码零侵入，扩展和修改方便，修改配置不需要重新编译代码
2、注解方式
	- 对业务代码低侵入，扩展和修改方便，但是修改配置需要重新编译代码
3、API调用方式
	- 对业务代码侵入较强，容易与某种具体的服务框架绑定，修改之后需要重新编译

服务灰度发布：

平滑升级，灰度发布的主要作用是：

1、解决服务升级不兼容的问题
2、及早获得用户的意见反馈，完善产品的功能，提升服务质量
3、缩小服务升级所影响的用户范围，降低升级风险
4、让用户及早参与产品测试，加强用户互动

参数传递：

参数传递可以考虑线程变量


流量控制：

当资源成为瓶颈时，服务框架需要对消费者做限流，启动流控保护机制。

1、静态流控，静态分配的阈值无法应用到云上，因为云的应用和服务是可以动态分配和调整的，可以采用动态配额分配制，但会引起贫富不均，可以使用动态配额申请制。

2、动态流控，最终目标就是为了保命，一个是动态流控因子，一个是分级流控


服务降级：

两种情况，

1、需要停掉一些不太重要的业务，例如商品评论，论坛和粉丝积分等
2、某些服务因为某种原因不可用，但是流程不能直接失败

服务降级主要包括 容错降级和屏蔽降级

屏蔽降级，非核心服务不发起远程服务调用，直接返回空，异常或者执行特定的本地逻辑，减少自身对公共资源的消费，把资源释放出来供核心服务使用，屏蔽降级的操作时可逆的，可以恢复到原来的服务

容错降级，将故障业务放通，容错逻辑主要包括两种，

1、RPC异常，超时异常，消息解码异常等
2、Service异常，例如登录校验失败，数据库操作失败

容错降级是根据服务调用的结果，自动匹配触发的，而屏蔽往往是通过人工根据系统运行情况手工操作触发的
容错降级是当服务提供者不可用时，让消费者执行业务放通，屏蔽降级主要是将原属于降级业务的资源调配出来供核心业务使用
调用机制不同，一个发起远程服务调用（容错降级），一个只做本地调用（屏蔽降级）

服务优先级调度：

有多种策略：

1、基于线程调度器的优先级调度策略
2、基于优先级队列的优先级调度策略
3、基于加权配置的优先级调度策略
4、基于服务迁入迁出的优先级调度策略

服务治理：

服务治理的历史变迁

第一代的 IBM的SOA Governance
第二代的 以分布式服务框架为中心的服务治理，阿里为首Dubbo
第三代的 微服务架构+云端服务治理，以AWS为首的，核心是服务微自治

服务治理的目标如下

1、防止业务服务架构腐化
2、快速故障定界定位，通过flume等分布式日志采集框架
3、服务微管控
4、服务生命周期管理

服务治理不是一个必选的部分

分布式消息跟踪：

把一次业务调用的完整轨迹以调用链的形式展现出来，核心就是调用链，用全局唯一的TraceID，通过ID将不同结点间的日志串接起来，形成一个完整的日志调用链

整体架构由4部分组成：

1、调用链埋点日志生成，埋点日志主要是客户端埋点和服务端埋点
2、分布式采集和存储埋点日志
3、在线、离线大数据计算，对调用链数据进行分析和汇总
4、调用链的界面展示、排序和检索

埋点日志也会面临如下挑战，

1、异步调用的时候，可能会发生线程切换，通过线程上下文传递的埋点信息丢失，会重新生成TraceID，导致调用链串接不起来
2、性能影响，JavaI/O通常是同步的，如果磁盘的WIO比较高，会导致写埋点日志阻塞应用线程

解决的思路

1、切换时要有线程上下文的备份，将埋点上下文复制到切换的线程上下文中
2、性能问题，支持异步写日志，例如log4j的appender，可灵活配置的埋点采样率，控制埋点日志量，批量写日志，日志流控机制

高QPS的应用，服务调用埋点本身的性能损耗也很大，为了解决100%全采样带来的性能损耗，可以通过采样率来实现埋点低损耗的目标

包括静态采样和动态采样，静态就是系统上线设置一个采样率，无论负载高低，按照该采样率执行，动态采样率根据系统的负载可以自动调整，负载低时100%采样，负载高时0%

用ES作为海量数据的存储策略，在用类似卡夫卡去作缓冲带，解决处理点跟不上发送日志的速度

可靠性设计：

微服务架构：

docker的优势，促进了微服务，

1、速度快，docker能够通过内核共享的方式，共享一套托管操作系统，所以docker的启停不需要几分钟，只要几百毫秒就够了，docker相比于物理机，计算能力不怎么消耗，但是vm就不同了，它增加了一层虚拟硬件层，应用进行数值计算是在Hypervisor虚拟的CPU上的，虚拟机虚拟的CPU架构不同于实际CPU架构
2、可移植性，不同的vm还要测试，但是只要跑docker，就不用了

高效的并发变成，**volatile的大量正确的使用，CAS和原子类的广泛使用，线程安全容器的使用，通过读写锁提升并发性能**

**分布式的事务**

如果原来非服务化的三个操作，被分配到三个微服务中，如果A，B提交成功，C不成功，那显然就会有事务不一致，所以可以用两阶段提交实现

阶段1、全局事务管理器向所有事务的参与者发送准备请求，事务参与者向全局事务管理器回复自己是否准备就绪
阶段2、全局事务管理器收到所有事务参与者的回复之后做判断，如果所有事务参与者都可以提交，则向所有事务提交者发送提交申请，否则进行回滚，事务参与者根据全局事务管理器的指令进行提交或者回滚操作

这是个悲观锁策略，如果全局事务管理器挂了，凉凉，所以，从功能上需要支持分布式事务，但在实际业务使用过程中，如果能够通过最终一致性解决问题，则不需要做强一致性，如果能够避免分布式事务则尽量避免使用分布式事务

真的需要吗，强一致性真的需要吗？大多数场景其实是能容忍短暂的不一致的，像转账，有几分钟的不一致还是可以容忍的，**可以使用最终一致性来替代传统的强一致性**，尽量避免分布式事务，最终方案可以是使用带事务功能的MQ做中间人的角色，先向MQ发送一个prepare消息，然后执行本地事务，本地事务提交成功后，向MQ发一个commit消息，否则发送一个rollback消息，MQ只会在收到commit确认才会将消息投递出去

多人开发，经常会相互等到，可以这样做，服务降级 或者 Mock测试

补充一些mock的知识，mock的使用背景

1、单元测试的思路就是我们想在不涉及依赖关系的情况下测试代码，在单元测试中，我们往往想去独立地去测一个类中的某个方法，但是这个类可不是独立的，它会去调用一些其它类的方法和service，这也就导致了以下两个问题，一个是外部服务可能无法在单元测试的环境中正常工作，因为它们可能需要访问数据库或者调用其它Http服务。一个是我们的测试关注点在于这个类的实现上，外部类的一些行为可能会影响到我们对本类的测试，那也就失去了我们进行单测的意义。

Mock测试就是在测试过程中，对那些不容易构建的对象，用一个虚拟对象来代替测试的情形。

Mock的框架有Mockito 和 PowerMock

Mockito是一个优秀的、最常用的单元测试mock框架，它能满足大部分时间的测试要求（public方法）

PowerMock可以去解决一些更难的问题（比如静态方法、私有方法、Final方法等）PowerMock 是在 EasyMock 以及 Mockito 基础上的扩展，通过提供定制的类加载器以及一些字节码篡改，实现更强大的测试功能
