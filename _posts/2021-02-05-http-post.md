---
layout: post
title: Http相关
tags: [http]
author-id: zqmalyssa
---

http，长连接，短连接

#### Http 和 长连接 和短连接

虽然在后端开发中，服务间调用已经广泛采用 RPC 技术。但是由于一些原因，例如像 Dubbo 停止维护、各厂自己的 RPC 框架还存在这样那样的问题、Open API 场景的大量存在等原因，HTTP 协议在后端开发中依然被广泛采用。为了提高 HTTP 接口的调用效率，HTTP 长连接是常见的优化手段。因此本文选择介绍一下 HTTP 和 TCP 长连接这个老生常谈的话题。

TCP 长连接是一种保持 TCP 连接的机制。当一个 TCP 连接建立之后，启用 TCP Keep Alive 的一端便会启动一个计时器，当这个计时器到达 0 之后，一个 TCP 探测包便会被发出。这个 TCP 探测包是一个纯 ACK 包，但是其 Seq 与上一个包是重复的。

TCP 连接两端好比两个人，这两个人之间保持通信往来（建立 TCP 连接）。如果他俩经常通信（经常发送 TCP 数据），那这个 TCP 连接自然是建立着的。但如果两人只是偶尔通信。那么，其中一个人（或两人同时）想知道对方是否还在，就会定期发送一份邮件（Keep Alive 探测包），这个邮件没有实质内容，只是问对方是否还在，如果对方收到，就会回复说还在（对这个探测包的 ACK 回应）。

需要注意的是，keep alive 技术只是 TCP 技术中的一个可选项。因为不当的配置可能会引起诸如一个正在被使用的 TCP 连接被提前关闭这样的问题，所以默认是关闭的

当需要建立 HTTP 长连接时，HTTP 请求头将包含如下内容：

```html

Connection: Keep-Alive

```

如果服务端同意建立长连接，HTTP 响应头也将包含如下内容：

```html

Connection: Keep-Alive

```

当需要关闭连接时，HTTP 头中会包含如下内容：

```html

Connection: Close

```

TCP Keep Alive 与 HTTP Keep Alive 的关系
如上文的解释，TCP Keep Alive 和 HTTP Keep Alive 是两个目的不同的技术，不存在谁依赖于谁的关系。TCP Keep Alive 用于探测对端是否存在，而 HTTP Keep Alive 用于协商以复用 TCP 连接。即便一个 TCP 连接未启用 Keep Alive 功能，也不妨碍 HTTP 层面开启长连接。

但如果 TCP Keep Alive 的 interval 数值设置果断，就可能导致 HTTP 无法重复利用已建立的 TCP 连接。


`HTTP 客户端配置`

```html

Apache HTTP Client

Apache HTTP Client 存在两种版本，在 3.x 版本时被称为 Commons HttpClient，4.x 后 Apache 创建了一个新的独立项目：Apache HttpComponents。这里指的是后者。

HttpClient buildHttpClient() {
    PoolingHttpClientConnectionManager connectionManager =
            new PoolingHttpClientConnectionManager(2, TimeUnit.MINUTES);
    connectionManager.setMaxTotal(DEFAULT_MAX_PER_ROUTE * 2);
    connectionManager.setDefaultMaxPerRoute(DEFAULT_MAX_PER_ROUTE);

    HttpClientBuilder builder = HttpClients.custom()
            .setConnectionManager(connectionManager);

    return builder.build();
}

上面这段代码展示了如何创建一个使用连接池的 HttpClient 的方法。当使用连接池后，HttpClient 就不必为每个请求创建一个单独的 TCP 连接了。


OkHttp

OkHttp 是国外的互联网支付公司 Square 的产品，优点是比较轻量，主要面向 Android 开发 使用，也可以使用在服务端开发场景中。使用 OkHttp 设置 HTTP 长连接比较简单，默认就会开启。只需创建一个 OkHttpClient 即可。

OkHttpClient client = new OkHttpClient();

这个 client 应该是单例的，因为它有自己的连接池。

不同于 Apache HTTP Client 的连接池，OkHttp 的连接池无法设置开启最大的连接数。有多少个线程使用 OkHttpClient 发送请求，其就会创建多少个连接。

OkHttp 实现 HTTP 连接池的组件是 ConnectionPool。虽然其不能设置最大连接数，但是可以设置最大空闲连接数和连接超时时间。

RestTemplate

RestTemplate 是 Spring 框架提供的 HTTP 客户端组件，适合调用 RESTful API 的场景。其并没有直接实现 HTTP 客户端功能，而是利用现有的组件。下面仅给出 RestTemplate 使用 Apache HTTP Client 时如何配置连接池：

@Profile("apache")
@Bean
public ClientHttpRequestFactory apacheHttpClientFactory() {
    return new CustomHttpComponentsClientHttpRequestFactory();
}

@Bean
public RestTemplate restTemplate(ClientHttpRequestFactory clientHttpRequestFactory) {
    RestTemplate restTemplate = new RestTemplate();
    restTemplate.setRequestFactory(clientHttpRequestFactory);
    return restTemplate;
}

static class CustomHttpComponentsClientHttpRequestFactory extends
        HttpComponentsClientHttpRequestFactory {
    CustomHttpComponentsClientHttpRequestFactory() {
        setHttpClient(buildHttpClient());
    }

    private HttpClient buildHttpClient() {
        PoolingHttpClientConnectionManager connectionManager =
                new PoolingHttpClientConnectionManager(2, TimeUnit.MINUTES);
        connectionManager.setMaxTotal(CONN_POOL_SIZE * 2);
        connectionManager.setDefaultMaxPerRoute(CONN_POOL_SIZE);

        HttpClientBuilder builder = HttpClients.custom()
                .setConnectionManager(connectionManager);

        return builder.build();
    }
}


```

`操作系统设置`

在 Linux 操作系统中，TCP Keep Alive 相关的配置可以在 /proc/sys/net/ipv4/ 目录中找到，具体有下面三个文件（括号中的是默认值）：

tcp_keepalive_time (7200)
tcp_keepalive_intvl (75)
tcp_keepalive_probes (9)

这边的设置 重启后就恢复默认值了

tcp_keepalive_time 的含义是在空闲相应时间（单位是秒）之后，TCP 协议栈将发送 Keep Alive 探测包；tcp_keepalive_intvl 的含义是开始探测之后每个探测包所间隔的时长，单位同样是秒；tcp_keepalive_probes 是探测包的个数。

默认的配置通常不适合一般的 Web 服务器，实际参数会远小于上述默认值。

正如前文所说，TCP Keep Alive 是用来检测 TCP 连接有效性的一种机制，如果一个空闲的 TCP 连接如果失效，那究竟多久能发现？假设采用如下配置：

tcp_keepalive_time = 60
tcp_keepalive_intvl = 10
tcp_keepalive_probes = 6
那将在 60 + 10 * 6 = 120s，即两分钟之后发现一个失效的 TCP 连接。

`Nginx Keep Alive 配置`

相较于有着丰富选择的 HTTP 客户端，在负载均衡服务器方面选择不是那么多，Nginx 是较为常见的选择。下面一段是启用了 HTTP 长连接的配置

```html

events {
    use                 epoll;
    worker_connections  102400;
}

http {
    upstream keepAliveService {
        server 10.10.131.149:8080;
        keepalive 20;
    }

    server {
        listen 80;
        server_name keepAliveService;
        location /keep-alive/hello {
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_pass http://keepAliveService;
        }
    }
}

```

上面这段配置中，对于 HTTP 长连接来说至关重要的有这么几项：

keepalive
proxy_http_verion
proxy_set_header
如果想要启用 HTTP 长连接，那这三项配置都是必须的。下面分别介绍。

keepalive

顾名思义，这个参数用于控制可连接整个 upstream servers 的 HTTP 长连接的个数，即控制总数。但需要注意的是，这个参数并不控制所有 upstream servers 连接的个数。（下文中超了就是短连接了）

proxy_http_verion

这个用于控制代理后端链接时使用的 HTTP 版本，默认为 1.0。要想使用长连接，必须配置为 1.1。除了 location 以外，这项配置还可以放在 http 和 server 这两级中。

proxy_set_header

除了要将 HTTP 协议设置为 1.1 以外，还要清空 Connection header 中的值。如果不配置 proxy_set_header Connection ""，则发往 upstream servers 的请求中，Connection header 的值将为 close，导致无法建立长连接。

同 proxy_http_version 一样，这项配置也可以放在 http 和 server 这两级中。

`应用服务器配置`

因为本文的示例程序使用 Spring Boot（版本为 1.5.2）开发，所以介绍 Spring Boot 中的两种应用服务：Tomcat 和 Undertow。

```html

Tomcat
Spring Boot 使用的 Tomcat 版本为 8.5.11，在使用默认配置情况下，每一个 HTTP 长连接会保持 10s 中，10s 之后，Tomcat 会主动断开连接。

从 HTTP 消息内容来看，虽然发往 Tomcat 的 HTTP 请求中带有 Connection: Keep-Alive，但是 Tomcat 提供的响应中并没有带有 Connection: Keep-Alive header。所以，严格来说，HTTP 长连接并没有建立成功（响应中没有包含 Connection: Keep-Alive 说明服务器端并没有同意建立长连接）。

但是，与 Tomcat 建立的连接确实被复用了，只是没有持续太长时间（10s）

Undertow
Undertow 是 JBoss 新推出的 Web 容器，特点在于高性能，有着远好于 Tomcat 的性能。

在对 HTTP 长连接支持方面，Undertow 的行为同 Tomcat 不同，不会主动关闭 HTTP 连接，也减少了建立、关闭 TCP 连接所带来的性能消耗。


```

`长连接与短连接的性能对比`

追求更好的性能通常是使用 HTTP 长连接的目的，那采用 HTTP 长连接之后，究竟有哪些性能提高？

```html

接口响应时间:

测试使用 JDK 8 编写的应用，应用服务器采用 Undertow，接口使用 Spring MVC 开发，接口耗时 100ms（Sleep 100ms），TPS 为 1000 左右，HTTP 客户端采用 Apache HTTP Client，配置 100 个连接的连接池，经过 Nginx 转发。非长连接模式是在 Nginx 配置中将 proxy_set_header Connection "" 去掉。

经过三次测试，在接口平均响应时间方面，使用长连接比不使用长连接少 1ms

服务器负载:

虽然接口平均响应时间方面差距不大，但是在服务器负载方面，应用长连接确有实实在在的好处。以 Nginx 服务器为例

top看nginx进程的负载，平均来看，在上述负载的情况下，使用长连接时 Nginx 的 CPU 占用率为 5% 左右，不使用长连接时为 9% 左右，可见差距还是比较明显的。也说明了使用长连接的好处，就是通过避免服务器频繁建立连接，降低服务器的负载。

```

`相关`

netstat中的 -o 参数，就是看 TCP Timers，有时候显示

```html

keepalive (6176.47/0/0)   // 表明 TCP 协议栈开启了 keep alive timers，后面括号中的值分别是 timer 所剩时长/重传次数/keepalive probe 次数

off (0.00/0/0)  // 表明没有开启 TCP keepalive timer

当然！！这个 timer 是否开启，和 HTTP keep alive 没有必然联系。上面说的两个概念

```

当查看服务器和客户端之间是否启用 HTTP keep alive 时，除了抓包以外，更为快速的方法是使用 netstat 命令看连接两次的端口是否不变。`如果客户端端口一直不变，说明服务端和客户端之间一直保持着同一个连接。`

但是，手工不停执行 netstat 命令不是个好办法，这里就要清楚 watch 命令。

```html

watch -n1 "netstat -anpo | grep :8080 | grep EST | grep 10.110.24.202"  // -n 后面带间隔时间

```

总结一下，首先 HTTP 和 TCP 的长连接（keep alive）是不同的机制，之间没有必然联系。而在 HTTP 方面，不同的客户端、服务器端产品的行为也是不同的：Apache HTTP Client 可以通过配置连接池、OkHttp 同样可以使用连接池，但是可配置的参数不多、RestTemplate 基于其它 HTTP Client 的实现；Nginx 默认不开启 HTTP 长连接，也需要配置，使用 HTTP 长连接可以降低 Nginx 负载；应用服务器对 HTTP 长连接的行为也有不同，需要分别对待。

#### 一些基本的补充，HttpCLient相关

持久连接的实现有两种：HTTP/1.0+的keep-alive与HTTP/1.1的持久连接（长连接），HTTP2加了 多路复用。

1、HTTP/1.0+的Keep-Alive

从1996年开始，很多HTTP/1.0浏览器与服务器都对协议进行了扩展，那就是“keep-alive”扩展协议。注意，这个扩展协议是作为1.0的补充的“实验型持久连接”出现的。keep-alive已经不再使用了，最新的HTTP/1.1规范中也没有对它进行说明，只是很多应用延续了下来。

使用HTTP/1.0的客户端在首部中加上"Connection:Keep-Alive"，请求服务端将一条连接保持在打开状态。服务端如果愿意将这条连接保持在打开状态，就会在响应中包含同样的首部。如果响应中没有包含"Connection:Keep-Alive"首部，则客户端会认为服务端不支持keep-alive，会在发送完响应报文之后关闭掉当前连接。

通过keep-alive补充协议，客户端与服务器之间完成了持久连接，然而仍然存在着一些问题：1 在HTTP/1.0中keep-alive不是标准协议，客户端必须发送Connection:Keep-Alive来激活keep-alive连接。 2 代理服务器可能无法支持keep-alive，因为一些代理是"盲中继"，无法理解首部的含义，只是将首部逐跳转发。所以可能造成客户端与服务端都保持了连接，但是代理不接受该连接上的数据。

2、HTTP/1.1的持久连接（长连接）

HTTP/1.1采取持久连接的方式替代了Keep-Alive。

HTTP/1.1的连接默认情况下都是持久连接。如果要显式关闭，需要在报文中加上Connection:Close首部。即在HTTP/1.1中，所有的连接都进行了复用。

然而如同Keep-Alive一样，空闲的持久连接也可以随时被客户端与服务端关闭。不发送Connection:Close不意味着服务器承诺连接永远保持打开。

3、HttpClien中使用了连接池来管理持久连接，同一条TCP链路上，连接是可以复用的。HttpClient通过连接池的方式进行连接持久化。

注意下面的4个问题:
a当有连接第一次使用的时候建立连接
b结束时对应连接不关闭，归还到池中
c下次同个目的的连接可从池中获取一个可用连接
d定期清理过期连接


连接池的实现

可以看到返回的ConnectionRequest对象实际上是一个持有了Future<CPoolEntry>，CPoolEntry是被连接池管理的真正连接实例。

  从上面的代码我们应该关注的是：

Future<CPoolEntry> future = this.pool.lease(route, state, null)
　　如何从连接池CPool中获得一个异步的连接，Future<CPoolEntry>
HttpClientConnection conn = leaseConnection(future, timeout, tunit)
　　如何通过异步连接Future<CPoolEntry>获得一个真正的连接HttpClientConnection

总结一下连接池

连接池有个最大连接数，每个route对应一个小连接池，也有个最大连接数
不论是大连接池还是小连接池，当超过数量的时候，都要通过LRU释放一些连接
如果拿到了可用连接，则返回给上层使用
如果没有拿到可用连接，HttpClient会判断当前route连接池是否已经超过了最大数量，没有到上限就会新建一个连接，并放入池中
如果到达了上限，就排队等待，等到了信号量，就重新获得一次，等待不到就抛超时异常
通过线程池获取连接要通过ReetrantLock加锁，保证线程安全

HttpClient如何判断一个连接在使用完毕后是要关闭，还是要放入池中供他人复用？

//如果reponse的Content-Length没有正确设置，则不复用连接
//因为对于持久化连接，两次传输之间不需要重新建立连接，则需要根据Content-Length确认内容属于哪次请求，以正确处理“粘包”现象
//所以，没有正确设置Content-Length的response连接不能复用

//如果response中没有相关的Connection首部说明，则高于HTTP/1.0版本的都复用连接

总结一下重用策略

如果request首部中包含Connection:Close，不复用
如果response中Content-Length长度设置不正确，不复用
如果response首部包含Connection:Close，不复用
如果reponse首部包含Connection:Keep-Alive，复用
都没命中的情况下，如果HTTP版本高于1.0则复用

定期处理过期连接

在HttpClient4.4版本之前，在从连接池中获取重用连接的时候会检查下是否过期，过期则清理。之后的版本则不同，会有一个单独的线程来扫描连接池中的连接，发现有离最近一次使用超过设置的时间后，就会清理。默认的超时时间是2秒钟。

总结

HttpClient通过连接池来管理持久连接，连接池分为两个，一个是总连接池，一个是每个route对应的连接池（有大小连接池）
HttpClient通过异步的Future<CPoolEntry>来获取一个池化的连接
默认连接重用策略与HTTP协议约束一致，根据response先判断Connection:Close则关闭，在判断Connection:Keep-Alive则开启，最后版本大于1.0则开启
只有在HttpClientBuilder中手动开启了清理过期与空闲连接的开关后，才会清理连接池中的连接
HttpClient4.4之后的版本通过一个死循环线程清理过期与空闲连接，该线程每次执行都sleep一会，以达到定期执行的效果


大小连接池，看下面的代码

```html

PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager();

1 //将最大连接数增加到200
2  cm.setMaxTotal(200);
3 //将每个路由的默认最大连接数增加到20
4  cm.setDefaultMaxPerRoute(20);


// 将http://www.baidu.com:80的最大连接增加到50，域名维度，覆盖路由的默认最大连接数
//HttpHost httpHost = new HttpHost("http://www.baidu.com",80);
//connectionManager.setMaxPerRoute(new HttpRoute(httpHost),50);

//发起3次GET请求
String url ="https://www.baidu.com/s?word=java";
long start = System.currentTimeMillis();
for (int i=0;i<100;i++){doGet(connectionManager,url);}
long end = System.currentTimeMillis();
System.out.println("consume -> " + (end - start));

```



#### Nginx 和 Tomcat 的 http 长连接设置

一个普通的请求是从浏览器到 Nginx，再从 Nginx 到 Tomcat。Tomcat 处理完后，再返回给 Nginx，最后再从 Nginx 返回给浏览器


在这个请求过程中，一般从浏览器到 Nginx 是短连接（就是请求回去后就断开连接），而 Nginx 到 Tomcat 可以是短连接 或是 长连接（请求返回后，连接还保持一段时间）。为什么 Nginx 到 Tomcat 之间要设置成长连接呢？因为连接的创建（三次握手）是需要花费一些时间的，如果请求量非常大，不如像连接池一样保存一定的连接，当有请求进来时复用一些连接。而且还能减少 time wait


请求方和被请求方都可以主动断开连接。请求方断开连接时机比较好判断，如果要请求的内容都完成了，就可以断开连接了。但被请求方的断开连接的时机就不好判断了，因为被请求方不知道请求方会发多少次请求。所以一般被请求方设置的参数相对多一些，例如：长连接在处理多少次请求后断开、长连接在经过多少秒后断开等等。


`Nginx的配置`

```html
1. Nginx - 反向代理
nginx.conf：

http { ... ## # 与Client连接的长连接配置 ## # http://nginx.org/en/docs/http/ngx_http_core_module.html#keepalive_requests # 设置通过"一个存活长连接"送达的最大请求数（默认是100，建议根据客户端在"keepalive"存活时间内的总请求数来设置） # 当送达到单个长连接的请求数超过该值后，该连接就会被关闭。（通过设置为5，验证确实是这样） keepalive_requests 8192; # http://nginx.org/en/docs/http/ngx_http_core_module.html#keepalive_timeout # 第一个参数设置"keep-alive客户端长连接"将在"服务器端"继续打开的超时时间（默认是75秒， # 建议根据具体业务要求来，但必须要求所有客户端连接的"Keep-Alive"头信息与该值设置的相同 # (这里是5分钟)，同时与上游服务器(Tomcat)的设置是一样的） # 可选的第二个参数设置“Keep-Alive: timeout=time”响应头字段的值。设置第二个参数后，这个时间会实传回给客户端（例如：浏览器） keepalive_timeout 300s 300s; ... include /etc/nginx/web_servers.conf;

}

web_servers.conf：
upstream web_server { server 127.0.0.1:8080; # http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive # 连接到 upstream（也就是 Tomcat）的最大并发空闲keepalive长连接数，也就是最多只能创建 # 这么多长连接，在这之上再创建连接的话，都是短连接。 #（默认是未设置，建议与Tomcat Connector中的maxKeepAliveRequests值一样）。 # 如果并发数大于这个数值的话，根据情况可能会创建一些`短连接`来处理请求。可以使用 # `netstat -an|grep TIME|awk '{if($4~"10001") print}'|wc -l`命令来查看， # 其中`10001`是 Nginx 的端口号，改成自己 Nginx 的端口。 # # 当这个数被超过时，使用"最近最少使用算法(LUR)"来淘汰并关闭连接。 keepalive 8;
}
server { listen 80; server_name lihg.com www.lihg.com; location / { proxy_pass http://web_server; ## # 与上游服务器(Tomcat)建立keepalive长连接的配置，可参考上面的keepalive链接里的 # "For HTTP"部分 ## # http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_http_version # 设置代理的HTTP协议版本（默认是1.0版本） # 使用keepalive连接的话，建议使用1.1版本。 proxy_http_version 1.1; # http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_set_header # 允许重新定义或追加字段到传递给代理服务器的请求头信息，默认是close。如果把这个 header 设置成空的话，Nginx 会向 Tomcat 传递`close`，这样 Tomcat 就会在处理完请求后关闭连接（这个部分是推理的，没有实际验证是 Tomcat 关的，还是 Nginx 关的） proxy_set_header Connection ""; }
}


```

keepalive_timeout 和 keepalive_requests 是影响长连接如何关闭的参数。 如果监控长连接在运行中，一部分的连接被关闭了（也就是没有了），可能是 keepalive_requests 影响的（因为超过了单个长连接的请求最大次数）；如果大批量被关闭了，可能是和 keepalive_timeout 有关。

upstream 中的 keepalive 是限制对 Tomcat 创建长连接个数的限制。不是不能创建超过这个数的连接，而是创建的长连接数，不能超过这个限制，在这之上可以再创建连接，只不过创建的都是短连接。
proxy_http_version 和 proxy_set_header 根据 http 版本（1.0/1.1）设置有所不同，请注意。

`Tomcat 设置`

maxKeepAliveRequests 属性和 Nginx 中的 keepalive_request 属性的功能是一样的，是互相影响的，即达到两边中最小的设置后关闭连接。如果 Tomcat 这边设置的是 5，而 Nginx 那边设置的是 10 的话，Tomcat 到 5 时就会关闭这个长连接。
keepAliveTimeout 属性和 Nginx 中的 keepalive_timeout 功能是一样的，也是互相影响的，同上。

如果使用是 Springboot 内嵌 Tomcat 的话，是无法在 application.properties 中设置 maxKeepAliveRequests 属性的。如果使用 Bean 的方式来设置，其它在 Springboot 中无法设置的属性也可以使用此方法来设置。另外，如果是在 application.properties 文件中设置了属性，也在 Bean 声明时设置了属性的话，application.properties 中设置的属性优先生效。

`测试`

为了测试长连接设置是否生效，可以使用下面两个命令来测试。

ab：用来进行压力测试的命令。例如：ab -c 8 -n 8000 127.0.0.1:10000/crm/，启用 8 个异步处理，发送总共 8000 个请求。
netstat：用来查看连接的状态。例如：netstat -an|grep ES|awk '{if($5~10001) print}'|wc -l，查看 Nginx 到 Tomcat 的正在使用连接。如果想要每秒刷新，可以这么做：while [ 1 -eq 1 ] ; do netstat -an|grep ES|awk '{if($5~10001) print}'|wc -l; sleep 1; echo ; done

上面脚本的端口号10001是nginx的端口号，替换成自己的

为了测试长连接是否起作用，最好把 Tomcat 部分按下面设置：

MaxKeepAliveRequests：设置成 -1。这样就不会因为请求个数，造成连接的断开和重新创建。用 netstat 查看连接时，看到的就是稳定的状态。
ConnectionTimeout：设置成一个比较大的值，例如 60 秒，这样不会因为压测时间长，造成连接的断开和重新创建。
Nginx 的 keepalive_requests 和 keepalive_timeout 和 Tomcat 上面两个值作用相同，最好设置成一样，以免造成不稳定，而不知道是哪出现的原因。

打开一个 Terminal，使用 ab 命令，进行压测：ab -c 8 -n 8000 127.0.0.1:10000/crm/

```html

This is ApacheBench, Version 2.3 <$revision:>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient)
Completed 800 requests
Completed 1600 requests
Completed 2400 requests
Completed 3200 requests
Completed 4000 requests
Completed 4800 requests
Completed 5600 requests
Completed 6400 requests
Completed 7200 requests
Completed 8000 requests
Finished 8000 requests


Server Software: nginx/1.15.1
Server Hostname: 127.0.0.1
Server Port: 10000

Document Path: /crm/
Document Length: 9 bytes

Concurrency Level: 8
Time taken for tests:   12.685 seconds
Complete requests: 8000
Failed requests: 0
Total transferred: 1304000 bytes
HTML transferred: 72000 bytes
Requests per second: 630.67 [#/sec] (mean)
Time per request: 12.685 [ms] (mean)
Time per request: 1.586 [ms] (mean, across all concurrent requests)
Transfer rate: 100.39 [Kbytes/sec] received

Connection Times (ms) min  mean[+/-sd] median   max
Connect: 0 1   5.0 0 147
Processing: 1   11  16.4 7 316
Waiting: 0   10  15.8 6 310
Total: 1   12  17.5 8 316

Percentage of the requests served within a certain time (ms)
  50% 8
  66% 12
  75% 15
  80% 16
  90% 23
  95% 30
  98% 45
  99% 78
 100% 316 (longest request)

```

查看连接状态命令输出如下。从下面输出可以看出，创建了 8 个长连接。连接的个数，应该和 Nginx 中 upstream 中的 keepalive 的参数一致。（这边应该是在nginx的服务器上压的）
