---
layout: post
title: probability
tags: [probability]
author-id: zqmalyssa
---

概率学，稍微要总结一下

#### 基本概念

条件概率

P(AB) = P(A)P(B|A)  // 下面是一个先验概率，在条件A下发生的概率，所以P(A)放在前面

贝叶斯公式就是一个后验概率，后验概率是通过先验概率去求解的。

分布函数 和 概率密度，去理解一下

```html

多维随机变量的（二维）的分布函数
F(x, y) = P(X<=x, Y<=y)

一维随机变量的分布函数
F(x) = P(X<=x)


然后密度函数是争对连续型随机变量的说的（离散型随机变量除外）

F(x) = 定积分f(x) 这样子的，下限是一个负无穷

f(x) 有很多种分布，均匀分布，指数分户，正态分布（u 和 sigema的取值影响函数的图像，u代表中轴的位置，而sigema代表抖憋度，sigema越大，y值越小，约平坦，sigema越大，y值越大，数值越集中）

f(x) 函数曲线到x轴往上的面积其实代表了F(x)，也就是概率P

分布函数F(x)是概率，那么 0 <= F(x) <= 1，另外0 <= F(x, y) <= 1

结合一些离散型的分布，两点分布、二项分布（伯努利）、泊松分布、几何分布

```

拓展到多个随机变量上去的话，就有多维分布函数 和 联合概率密度

```html

F(x, y) = 多重积分f(x, y) 这样子的，x的下限是一个负无穷，y的下限是一个负无穷

概率密度的性质

f(x, y) >= 0

取正无穷的双重积分最后值为1（归一性）

对应的，有二维均匀分布，二维指数分布，二维正态分布（二维正态分布的相关系数就为肉 -1 <= 肉 <= 1，一共5个参数了，u_1，u_2，sigema_1，sigema_2，还有肉）

离散型随机变量只有分布律，连续型随机变量才有概率密度（有概率密度也好算期望）

F(x, y) = F_X(x) * F_Y(y) ，则说X、Y相互独立

// 用概率去求解，对于离散型，需要检验所有分布律的值
P(X=x_i, Y=y_i) = P(X=x_i)P(Y=y_i)

// 对于连续型
f(x, y) = f_X(x)f_Y(y)处处成立，就代表了独立性

独立的积分区域一般是方方正正的，若积分区域不方正，则需考虑是否独立

```

如果(X, Y)的概率密度是 f(x, y)，若X 和 Y相互独立，则Z = X + Y的密度函数公式称为卷积公式：

```html

f_Z(z) = 定积分f_X(z-y)f_Y(y) dy = 定积分f_X(x)f_Y(z-x) dx

另外 f 可以从 F求导得到

X、Y相互独立，X ~ N(u_1, sigema_1的平方)，Y ~ N(u_2, sigema_2的平方)。则有 Z = X + Y ~ N(u_1 + u_2, sigema_1的平方 + sigema_2的平方)

上面是正态分布很特别的定义

那么离散变量的“独立和”分布：

X_1，X_2，X_3，X_4均服从（0-1）分布，那么X_1 + X_2 + X_3 + X_4 ~ B(n, p)服从伯努利分布（二项分布）

X ~ 泊松(namuda_1)，Y ~ 泊松(namuda_2)，两者独立，则X + Y ~ 泊松(namuda_1 + namuda_2)

```

independent identically distributed（独立同分布），这个在太多地方用到了

一维随机变量的数学期望（均值）

记作E(X)，x_i * p_i 全部相加得到

连续型随机变量的数学期望（均值），就要用到积分了，均值的意思其实就是加权平均，也就是这些数值中的平均值，这里的样本n乘上权重p后再做分母的时候n是可以约掉的

X有密度函数的时候算期望，也是通过定积分去算的

```html

投掷一颗均匀的骰子，赌客猜出精确的骰子点数，猜中者以1:5得到奖金，否则其押金归庄家所有，问此规则对庄家有利还是对赌客有利

赌客押了10元

设X为赌客最终输赢数

X的取值是： -10，40

P(X = -10) = 5 / 6

P(X = 40) = 1 / 6

可以写出分布律，然后算期望，E(X) = - 5 / 3，约等于-1.67元，就是说1把 到 1万把，那么最终状态肯定是亏钱的。肯定是对庄家有利，对赌客无利的

拓展一下，这边是1:5的奖金，那么如果是1:100的奖金呢，期望E(Y) 算一下是多少呢，E(Y) = 156.66666 （这就是正的了啊，哇哦，所以这种一直玩就是正的）

这个概率模型就出来了

```

二维随机变量的数学期望，用双重定积分去做

方差本质就是偏离均值的程度，离着均值比较近就是方差小，离着均值远就是方差大

方差也可以用数学期望去算，E((X - E(X))的平方)去算的，结果就是X的方差。记作D(X)。D(X)的开根号代表标准差或者均方差

D(X) = E(X的平方) - (E(X))的平方 // 简单点记忆就是 内方 - 外方

D(a) = 0 （a是常数的话，方差为0，常数是话就是没有偏离程度了）

如果X，Y相互独立，那么D(X +- Y) = D(X) +- D(Y)

如果方差 D(X) = 0，那么 P(X=C) = 1 且 C = E(X)，就是全部取到均值了（只要有偏离，都会有方差）


正态分布就是 N(u, sigema的平方)，那么这里u是期望，sigema的平方是方差，sigema就是标准差


协方差 和 相关系数，

协方差Cov(X, Y) = E{[X - E(X)][Y - E(Y)]} = E(XY) - E(X)E(Y) = E(XY) - E(X)E(Y)

相关系数 肉_XY = Cov(X, Y) / [D(X)D(Y)]的开根号

Cov(X, X) = D(X)

肉_xy 的绝对值 是 <= 1的，如果绝对值是等于1的，就是说线性相关性比较强，就是线性关系的程度较好。误差较小。另外大于0的时候，X与Y是正相关的，小于0的时候，是负相关的

特殊的，如果肉_xy 等于0，就是不相关（零相关）（这边试试图片呢？？）（gpt可以给你举例子表示，1、掷硬币和投色子 是完全独立事件，掷硬币的正反面不会影响投色子的值，所以是独立不相关，2、气温和冰淇淋销量，气温的高低影响冰淇淋的销量，随机变量是相关的，所以相关不独立（看下面的定理），3、X是-1到1的均匀分布，Y=X的平方，X和Y的线性相关系数，也就是肉是0，为不相关，但是Y又能从X求得，所以是不独立的，就是又不独立又不相关的，只能说它们有非线性关系，图像就是一个U）

如有X ~ U(-1, 1)， 而Y = X的平方，求一下Cov(X, Y)，直接用公式 E(XY) - E(X)E(Y)，然后把Y=X的平方带入求解就得到确实是0。。。

独立可以推出不相关、相关可以推出不独立，不能反着推过去。独立就是上面说的离散用分布律，连续用密度函数去推断的

如果看似独立的，先判断独立性，因为若真的独立了，则一定不相关，不必再求各期望了

如果看似不独立的，先判断相关性，因为若相关则不独立，不必再求边际分布了

中心极限定理，其实很重要的就是独立同分布的随机变量，最终都可以类似于服从正态分布，也就是通过累加的求取期望和方差，就能得到 ~ N(u, sigema的平方)

之后就进入数理统计学的部分，之前都是概率论部分。是一门关于数据收集、整理、分析和推断的科学

样本基本是指 简单随机样本，也就是独立同分布

样本均值、样本方差（除以n-1，这里涉及的是自由度的问题，所以这边的方差跟上面定义是有点不一样的）

X_1，X_2，X_3，X_n是总体X的样本，若E(X) = a，D(X) = b的平方，那么样本的期望的 期望和方差呢，是这样的，E(X') = E(X)，D(X') = D(X) / n = b的平方 / n

对于E(S的平方) 和 D(S的平方)，也要计算一下，就是样本方差的 期望和方差，E(S的平方) = b的平方，D(S的平方) = 2sigema的四次方 / n - 1

连续型的随机变量取一个常熟的概率 为 0 。。。

样本的一些分布，卡方分布（n为自由度，当n足够大的时候，就近似正态分布，但注意不是对称的。注意这个前提是服从 标准正态分布）、t分布（t分布的极限是标准正态分布，关于y轴对称，比标准正态分布图形平坦）、F分布（很多性质可以由前面推导出来，上面几个都需要查表 根据分位数求解值）等等

标准正态分布 N(0, 1)，可以将 x -u / sigema 得出，所有均服从 标准正态分布

如果总体是个正态分布，那么抽样会满足一些性质的：一个上面求出的样本符合一个正态分布X' ~ N(u, sigema的平方 / n)，这里的X'代表的是样本均值！！！，一个是X' - u / S/根号n 是符合自由度为n-1的t分布，最后一个不怎么用的是关于样本均值和样本方差相互独立且符合一个卡方分布的

下面一节是参数估计相关，就是通过样本的情况去估计总体的情况，参数估计是统计推断的基本问题之一，实际工作中碰到的总体X它的分布类型往往是知道的，只是不知道其中的某些参数，例如产品质量指标X服从正态分布，但是你的u 和 sigema的平方未知，参数估计的两种方法，点估计法和区间估计法

点估计法 有 矩估计法，顺序统计量法，极大似然估计法 等方法（矩估计法，抽取的样本不同，值不一样，等于期望先求出来，如果包含未知参数就可解，如果不包含，就求下阶矩估计），极大似然估计就是观察结果的概率偏大的那个值的p，似然意思就是 好像的意思。有离散型 和 连续型。连续型的就是有个似然函数，各样本的连乘函数L，然后求出L的极大值点，那么就要求导，取对数，可得对数似然函数，再对估计的参数求导。估计量 和 估计值一个是 大X，一个是小x，要注意。一般不做是否为极大值检验。离散一样的，就是一个L极大似然函数，分布相乘。极大似然估计 和 矩估计得出的结果是不一样的

估计量的评判标准一个是 无偏性，一个是 有效性，还有一个是一致性（用切比雪诺不等式）。

区间估计法 估计也得有个可靠度，置信度，就是在区间估计里面。实际问题中，有时候给出未知参数的一个估计值是没有什么价值的，而是需要估计其取值范围，例如每天的天气预报，有最低和最高气温，可以看作是一个区间估计。-50度 - 50度，100%是正确的，改成 15度 - 40度，就是95%的把握，再改成 25度 - 35度，也许只有85%的可靠度了。上面就分别是 置信区间 和 置信度相关。会给定一个枢轴量（有4种，对应不同的分布，用来求解u 或者是sigema的平方）取求解一些问题，比如置信度为多少的置信区间

之后就是一个假设检验专题了，药品贮藏寿命均值180天，标准差不多于10天的正态分布，使用者担心标准差可能超过10天，随机选取12个样品并测试，得到样本的标准差为14天，根据样本有充分证据证明标准差大于10天么

```html

基于上面的例子，如果一些随机数，6、9、13、17、20、23、28、31、33、40，均值是22，总体标准差10.48，样本标准差11.05，所以方差是每个数偏移量平方的平均，标准差是每个数偏移量的平均，标准差在原单位上更能表现出偏移，所以上面的药品例子用的是标准差

```

接受域，如果落到接受域内，则认为假设成立。先找出原假设和备选假设，构造一个接受域。一般将问的肯定句作为H_1，假设检验思想中，拒绝是主动的，而接受是被动的。这个直接看视频的例子。根据样本来的，还是有点用的
